{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"! pip install sacrebleu --quiet","metadata":{"execution":{"iopub.status.busy":"2023-03-08T09:19:16.019158Z","iopub.execute_input":"2023-03-08T09:19:16.019685Z","iopub.status.idle":"2023-03-08T09:19:28.902309Z","shell.execute_reply.started":"2023-03-08T09:19:16.019655Z","shell.execute_reply":"2023-03-08T09:19:28.901096Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"# let's import all necessary dependencies\n\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nimport os\nfrom datasets import Dataset\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nos.environ[\"WANDB_DISABLED\"] = 'true'","metadata":{"execution":{"iopub.status.busy":"2023-03-08T09:19:28.904508Z","iopub.execute_input":"2023-03-08T09:19:28.904828Z","iopub.status.idle":"2023-03-08T09:19:36.516112Z","shell.execute_reply.started":"2023-03-08T09:19:28.904796Z","shell.execute_reply":"2023-03-08T09:19:36.515060Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"dataset = pd.read_csv('/kaggle/input/english-french-translation/fr-en-translation.csv', nrows=100000, encoding_errors='ignore')\n\ndataset = dataset.loc[:, dataset.columns != 'Unnamed: 2']\n\ndataset.head()","metadata":{"execution":{"iopub.status.busy":"2023-03-08T09:19:36.518001Z","iopub.execute_input":"2023-03-08T09:19:36.518855Z","iopub.status.idle":"2023-03-08T09:19:37.121081Z","shell.execute_reply.started":"2023-03-08T09:19:36.518809Z","shell.execute_reply":"2023-03-08T09:19:37.119849Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"                                                   1  \\\n0   You thought to this day that there were tyrants?   \n1                      How do you feed your family?\"   \n2  The first group shows God creating the Heavens...   \n3  It is said after this he split to a thousand p...   \n4  They are subservient to him, and created for a...   \n\n                                                   2  \n0  Vous avez cru jusqu'à ce jour qu'il y avait de...  \n1           Comment nourrissez-vous votre famille ?\"  \n2  Le premier ciel est une voûte à laquelle la te...  \n3  Il est dit après cela, qu'il s'est divisé en m...  \n4  Ils sont serviles à son égard, et créés pour u...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>1</th>\n      <th>2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>You thought to this day that there were tyrants?</td>\n      <td>Vous avez cru jusqu'à ce jour qu'il y avait de...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>How do you feed your family?\"</td>\n      <td>Comment nourrissez-vous votre famille ?\"</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>The first group shows God creating the Heavens...</td>\n      <td>Le premier ciel est une voûte à laquelle la te...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>It is said after this he split to a thousand p...</td>\n      <td>Il est dit après cela, qu'il s'est divisé en m...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>They are subservient to him, and created for a...</td>\n      <td>Ils sont serviles à son égard, et créés pour u...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# let's use HuggingFace's Dataset object\ndataset = Dataset.from_pandas(dataset)\n\ndataset","metadata":{"execution":{"iopub.status.busy":"2023-03-08T09:19:37.124923Z","iopub.execute_input":"2023-03-08T09:19:37.125798Z","iopub.status.idle":"2023-03-08T09:19:37.222575Z","shell.execute_reply.started":"2023-03-08T09:19:37.125756Z","shell.execute_reply":"2023-03-08T09:19:37.221560Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['1', '2'],\n    num_rows: 100000\n})"},"metadata":{}}]},{"cell_type":"code","source":"# let's split the dataset into train and validation datasets\nfrom sklearn.model_selection import train_test_split\nfrom typing import Tuple\n\ndef split_dataset(dataset: Dataset) -> Tuple[Dataset, Dataset]:\n    \"\"\"\n    Split a HuggingFace Dataset object into training and validation sets.\n\n    Args:\n        dataset (Dataset): The dataset to split.\n\n    Returns:\n        Tuple[Dataset, Dataset]: A tuple containing the training and validation datasets.\n    \"\"\"\n    # Extract the texts and labels from the dataset\n    texts = dataset['1']\n    labels = dataset['2']\n    \n    # Split the dataset into training and validation sets\n    train_texts, val_texts, train_labels, val_labels = train_test_split(texts, labels, test_size=0.2)\n\n    # Create new Dataset objects for the training and validation sets\n    train_dataset = Dataset.from_dict({'english': train_texts, 'french': train_labels})\n    val_dataset = Dataset.from_dict({'english': val_texts, 'french': val_labels})\n    \n    return train_dataset, val_dataset","metadata":{"execution":{"iopub.status.busy":"2023-03-08T09:19:37.224322Z","iopub.execute_input":"2023-03-08T09:19:37.224667Z","iopub.status.idle":"2023-03-08T09:19:37.712714Z","shell.execute_reply.started":"2023-03-08T09:19:37.224629Z","shell.execute_reply":"2023-03-08T09:19:37.711687Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"train_dataset, val_dataset = split_dataset(dataset)\nprint(len(train_dataset), len(val_dataset))","metadata":{"execution":{"iopub.status.busy":"2023-03-08T09:19:37.714038Z","iopub.execute_input":"2023-03-08T09:19:37.714415Z","iopub.status.idle":"2023-03-08T09:19:38.105148Z","shell.execute_reply.started":"2023-03-08T09:19:37.714376Z","shell.execute_reply":"2023-03-08T09:19:38.103949Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"80000 20000\n","output_type":"stream"}]},{"cell_type":"code","source":"train_dataset['english'][:3]","metadata":{"execution":{"iopub.status.busy":"2023-03-08T09:19:38.106765Z","iopub.execute_input":"2023-03-08T09:19:38.107161Z","iopub.status.idle":"2023-03-08T09:19:38.182292Z","shell.execute_reply.started":"2023-03-08T09:19:38.107121Z","shell.execute_reply":"2023-03-08T09:19:38.181188Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"['Lincoln wanted to win; Davis wanted to be right.',\n 'But he also notes that \"if Joshua Prawer were alive today he would no doubt deny any linkage between his Zionist political beliefs and the model of segregation that he developed.\"',\n 'On 1 September 1920, the Weimar Republic and Austria concluded an economic agreement.']"},"metadata":{}}]},{"cell_type":"code","source":"train_dataset['french'][:3]","metadata":{"execution":{"iopub.status.busy":"2023-03-08T09:19:38.184041Z","iopub.execute_input":"2023-03-08T09:19:38.184802Z","iopub.status.idle":"2023-03-08T09:19:38.284731Z","shell.execute_reply.started":"2023-03-08T09:19:38.184762Z","shell.execute_reply":"2023-03-08T09:19:38.283289Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"['Lincoln voulait gagner\\xa0; Davis voulait être juste.',\n \"Il nota aussi que «\\xa0si Joshua Prawer était vivant aujourd'hui, il nierait sans aucun doute toute filiation entre ses croyances politiques sionistes et le modèle de ségrégation qu'il a développé\\xa0».\",\n \"Le 1er septembre 1920, la République de Weimar et l'Autriche signèrent un accord économique.\"]"},"metadata":{}}]},{"cell_type":"markdown","source":"### Loading From HuggingFace","metadata":{}},{"cell_type":"code","source":"# some stuff \n\nmaxlen = 40\nbatch_size = 64\nepochs = 5","metadata":{"execution":{"iopub.status.busy":"2023-03-08T09:19:38.286614Z","iopub.execute_input":"2023-03-08T09:19:38.287034Z","iopub.status.idle":"2023-03-08T09:19:38.292631Z","shell.execute_reply.started":"2023-03-08T09:19:38.286995Z","shell.execute_reply":"2023-03-08T09:19:38.291445Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# load the tokenizer from huggingface\nfrom transformers import AutoTokenizer\n\nmodel_name = 'Helsinki-NLP/opus-mt-en-fr'\n\ntokenizer = AutoTokenizer.from_pretrained(model_name)","metadata":{"execution":{"iopub.status.busy":"2023-03-08T09:19:38.298031Z","iopub.execute_input":"2023-03-08T09:19:38.298709Z","iopub.status.idle":"2023-03-08T09:19:45.066708Z","shell.execute_reply.started":"2023-03-08T09:19:38.298655Z","shell.execute_reply":"2023-03-08T09:19:45.065559Z"},"trusted":true},"execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading (…)okenizer_config.json:   0%|          | 0.00/42.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7dffdbf15d15446c932b408a2aed147c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)lve/main/config.json:   0%|          | 0.00/1.42k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ad3308207e134fb8aee48dd3e716e01e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)olve/main/source.spm:   0%|          | 0.00/778k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8233d7c199f245c9bfc69c08b067fe94"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)olve/main/target.spm:   0%|          | 0.00/802k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0a3d1614ad3c4636ba12ef412ac6b072"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)olve/main/vocab.json:   0%|          | 0.00/1.34M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a66723971f4f4c2d8588eb717fb96f85"}},"metadata":{}}]},{"cell_type":"code","source":"from transformers import AutoModelForSeq2SeqLM\n\nmodel = AutoModelForSeq2SeqLM.from_pretrained(model_name)","metadata":{"execution":{"iopub.status.busy":"2023-03-08T09:19:45.068470Z","iopub.execute_input":"2023-03-08T09:19:45.068871Z","iopub.status.idle":"2023-03-08T09:19:53.287870Z","shell.execute_reply.started":"2023-03-08T09:19:45.068829Z","shell.execute_reply":"2023-03-08T09:19:53.286644Z"},"trusted":true},"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading (…)\"pytorch_model.bin\";:   0%|          | 0.00/301M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b7f1e0ccae5e44a59a3a0e6ebe33244e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)neration_config.json:   0%|          | 0.00/293 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0a9235cf6c634a81b764e99a6f7f805b"}},"metadata":{}}]},{"cell_type":"code","source":"text = \"This is how the model tokenizes text.\"\n\ntokenized_text = tokenizer(text, add_special_tokens = False)\ntokenized_text","metadata":{"execution":{"iopub.status.busy":"2023-03-08T09:19:53.289768Z","iopub.execute_input":"2023-03-08T09:19:53.291071Z","iopub.status.idle":"2023-03-08T09:19:53.299972Z","shell.execute_reply.started":"2023-03-08T09:19:53.291025Z","shell.execute_reply":"2023-03-08T09:19:53.298909Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"{'input_ids': [160, 32, 541, 4, 2223, 12, 7106, 3317, 9, 1863, 3], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"},"metadata":{}}]},{"cell_type":"code","source":"def preprocess_dataset(dataset):\n    \"\"\"Utility function to batch encode the texts in the dataset\"\"\"\n    \n    inputs = [text for text in dataset['english']]\n    targets = [text for text in dataset['french']]\n    model_inputs = tokenizer(inputs, max_length = maxlen, truncation = True)\n    \n    with tokenizer.as_target_tokenizer():\n        labels = tokenizer(targets, max_length = maxlen, truncation = True)\n    \n    model_inputs['labels'] = labels['input_ids']\n    return model_inputs","metadata":{"execution":{"iopub.status.busy":"2023-03-08T09:19:53.303768Z","iopub.execute_input":"2023-03-08T09:19:53.304384Z","iopub.status.idle":"2023-03-08T09:19:53.330727Z","shell.execute_reply.started":"2023-03-08T09:19:53.304345Z","shell.execute_reply":"2023-03-08T09:19:53.329274Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"train_dataset = train_dataset.map(preprocess_dataset, batched = True)\nval_dataset = val_dataset.map(preprocess_dataset, batched = True)","metadata":{"execution":{"iopub.status.busy":"2023-03-08T09:19:53.332383Z","iopub.execute_input":"2023-03-08T09:19:53.332827Z","iopub.status.idle":"2023-03-08T09:20:23.904782Z","shell.execute_reply.started":"2023-03-08T09:19:53.332791Z","shell.execute_reply":"2023-03-08T09:20:23.903855Z"},"trusted":true},"execution_count":14,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/80 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"df9f72cabd1049a998457140398a162c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/20 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"69304b76cefd4203b027b58f2316109f"}},"metadata":{}}]},{"cell_type":"code","source":"train_dataset","metadata":{"execution":{"iopub.status.busy":"2023-03-08T09:20:23.906296Z","iopub.execute_input":"2023-03-08T09:20:23.906894Z","iopub.status.idle":"2023-03-08T09:20:23.913968Z","shell.execute_reply.started":"2023-03-08T09:20:23.906837Z","shell.execute_reply":"2023-03-08T09:20:23.912621Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['english', 'french', 'input_ids', 'attention_mask', 'labels'],\n    num_rows: 80000\n})"},"metadata":{}}]},{"cell_type":"code","source":"from transformers import DataCollatorForSeq2Seq\n\ndata_collator = DataCollatorForSeq2Seq(tokenizer,  model = model)","metadata":{"execution":{"iopub.status.busy":"2023-03-08T09:20:23.915359Z","iopub.execute_input":"2023-03-08T09:20:23.916402Z","iopub.status.idle":"2023-03-08T09:20:23.937787Z","shell.execute_reply.started":"2023-03-08T09:20:23.916343Z","shell.execute_reply":"2023-03-08T09:20:23.936915Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"## Training","metadata":{}},{"cell_type":"code","source":"from transformers import Seq2SeqTrainingArguments\n\ntraining_arguments = Seq2SeqTrainingArguments(output_dir = 'model_checkpoint', #evaluation_strategy = 'epoch',\n                                             learning_rate=2e-5, per_device_train_batch_size = batch_size,\n                                              #per_device_eval_batch_size=batch_size,\n                                             weight_decay = 0.01, num_train_epochs = epochs,\n                                             save_total_limit = 3, fp16 = True)","metadata":{"execution":{"iopub.status.busy":"2023-03-08T09:20:23.939063Z","iopub.execute_input":"2023-03-08T09:20:23.939490Z","iopub.status.idle":"2023-03-08T09:20:24.040195Z","shell.execute_reply.started":"2023-03-08T09:20:23.939450Z","shell.execute_reply":"2023-03-08T09:20:24.038928Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stderr","text":"Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n","output_type":"stream"}]},{"cell_type":"code","source":"from datasets import load_metric\n\nmetric = load_metric('sacrebleu')","metadata":{"execution":{"iopub.status.busy":"2023-03-08T09:20:24.042114Z","iopub.execute_input":"2023-03-08T09:20:24.042920Z","iopub.status.idle":"2023-03-08T09:20:24.756376Z","shell.execute_reply.started":"2023-03-08T09:20:24.042851Z","shell.execute_reply":"2023-03-08T09:20:24.755349Z"},"trusted":true},"execution_count":18,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/2.85k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d5eafb59a71b4f2ca1875389db62d93a"}},"metadata":{}}]},{"cell_type":"code","source":"def postprocess_text(preds, labels):\n    preds = [pred.strip() for pred in preds]\n    labels = [label.strip() for label in labels]\n    \n    return preds, labels","metadata":{"execution":{"iopub.status.busy":"2023-03-08T09:20:24.757863Z","iopub.execute_input":"2023-03-08T09:20:24.758692Z","iopub.status.idle":"2023-03-08T09:20:24.765517Z","shell.execute_reply.started":"2023-03-08T09:20:24.758647Z","shell.execute_reply":"2023-03-08T09:20:24.763550Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"def compute_metrics(eval_preds):\n    preds, labels = eval_preds\n    \n    if isinstance(preds, tuple):\n        preds = preds[0]\n    \n    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens = True)\n    \n    # Replace -100 in the labels as we can't decode them.\n    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n    \n    # Some simple post-processing\n    decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels)\n\n    result = metric.compute(predictions=decoded_preds, references=decoded_labels)\n    result = {\"bleu\": result[\"score\"]}\n\n    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds]\n    result[\"gen_len\"] = np.mean(prediction_lens)\n    result = {k: round(v, 4) for k, v in result.items()}\n    \n    return result","metadata":{"execution":{"iopub.status.busy":"2023-03-08T09:20:24.766995Z","iopub.execute_input":"2023-03-08T09:20:24.768007Z","iopub.status.idle":"2023-03-08T09:20:24.777958Z","shell.execute_reply.started":"2023-03-08T09:20:24.767968Z","shell.execute_reply":"2023-03-08T09:20:24.776868Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"from transformers import Seq2SeqTrainer\n\ntrainer = Seq2SeqTrainer(model, training_arguments, train_dataset = train_dataset, \n                         data_collator = data_collator, #eval_dataset = val_dataset,\n                         tokenizer = tokenizer, compute_metrics = compute_metrics)","metadata":{"execution":{"iopub.status.busy":"2023-03-08T09:20:24.779402Z","iopub.execute_input":"2023-03-08T09:20:24.780004Z","iopub.status.idle":"2023-03-08T09:20:29.137812Z","shell.execute_reply.started":"2023-03-08T09:20:24.779967Z","shell.execute_reply":"2023-03-08T09:20:29.136827Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stderr","text":"Using cuda_amp half precision backend\n","output_type":"stream"}]},{"cell_type":"code","source":"trainer.train()","metadata":{"execution":{"iopub.status.busy":"2023-03-08T09:20:29.139508Z","iopub.execute_input":"2023-03-08T09:20:29.139897Z","iopub.status.idle":"2023-03-08T09:48:08.036833Z","shell.execute_reply.started":"2023-03-08T09:20:29.139843Z","shell.execute_reply":"2023-03-08T09:48:08.035862Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stderr","text":"The following columns in the training set don't have a corresponding argument in `MarianMTModel.forward` and have been ignored: french, english. If french, english are not expected by `MarianMTModel.forward`,  you can safely ignore this message.\n***** Running training *****\n  Num examples = 80000\n  Num Epochs = 5\n  Instantaneous batch size per device = 64\n  Total train batch size (w. parallel, distributed & accumulation) = 64\n  Gradient Accumulation steps = 1\n  Total optimization steps = 6250\n  Number of trainable parameters = 74609664\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='6250' max='6250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [6250/6250 27:36, Epoch 5/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>500</td>\n      <td>0.685200</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>0.642500</td>\n    </tr>\n    <tr>\n      <td>1500</td>\n      <td>0.612600</td>\n    </tr>\n    <tr>\n      <td>2000</td>\n      <td>0.582400</td>\n    </tr>\n    <tr>\n      <td>2500</td>\n      <td>0.581800</td>\n    </tr>\n    <tr>\n      <td>3000</td>\n      <td>0.537400</td>\n    </tr>\n    <tr>\n      <td>3500</td>\n      <td>0.542900</td>\n    </tr>\n    <tr>\n      <td>4000</td>\n      <td>0.526900</td>\n    </tr>\n    <tr>\n      <td>4500</td>\n      <td>0.511000</td>\n    </tr>\n    <tr>\n      <td>5000</td>\n      <td>0.514200</td>\n    </tr>\n    <tr>\n      <td>5500</td>\n      <td>0.495300</td>\n    </tr>\n    <tr>\n      <td>6000</td>\n      <td>0.498800</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"Saving model checkpoint to model_checkpoint/checkpoint-500\nConfiguration saved in model_checkpoint/checkpoint-500/config.json\nConfiguration saved in model_checkpoint/checkpoint-500/generation_config.json\nModel weights saved in model_checkpoint/checkpoint-500/pytorch_model.bin\ntokenizer config file saved in model_checkpoint/checkpoint-500/tokenizer_config.json\nSpecial tokens file saved in model_checkpoint/checkpoint-500/special_tokens_map.json\nSaving model checkpoint to model_checkpoint/checkpoint-1000\nConfiguration saved in model_checkpoint/checkpoint-1000/config.json\nConfiguration saved in model_checkpoint/checkpoint-1000/generation_config.json\nModel weights saved in model_checkpoint/checkpoint-1000/pytorch_model.bin\ntokenizer config file saved in model_checkpoint/checkpoint-1000/tokenizer_config.json\nSpecial tokens file saved in model_checkpoint/checkpoint-1000/special_tokens_map.json\nSaving model checkpoint to model_checkpoint/checkpoint-1500\nConfiguration saved in model_checkpoint/checkpoint-1500/config.json\nConfiguration saved in model_checkpoint/checkpoint-1500/generation_config.json\nModel weights saved in model_checkpoint/checkpoint-1500/pytorch_model.bin\ntokenizer config file saved in model_checkpoint/checkpoint-1500/tokenizer_config.json\nSpecial tokens file saved in model_checkpoint/checkpoint-1500/special_tokens_map.json\nSaving model checkpoint to model_checkpoint/checkpoint-2000\nConfiguration saved in model_checkpoint/checkpoint-2000/config.json\nConfiguration saved in model_checkpoint/checkpoint-2000/generation_config.json\nModel weights saved in model_checkpoint/checkpoint-2000/pytorch_model.bin\ntokenizer config file saved in model_checkpoint/checkpoint-2000/tokenizer_config.json\nSpecial tokens file saved in model_checkpoint/checkpoint-2000/special_tokens_map.json\nDeleting older checkpoint [model_checkpoint/checkpoint-500] due to args.save_total_limit\nSaving model checkpoint to model_checkpoint/checkpoint-2500\nConfiguration saved in model_checkpoint/checkpoint-2500/config.json\nConfiguration saved in model_checkpoint/checkpoint-2500/generation_config.json\nModel weights saved in model_checkpoint/checkpoint-2500/pytorch_model.bin\ntokenizer config file saved in model_checkpoint/checkpoint-2500/tokenizer_config.json\nSpecial tokens file saved in model_checkpoint/checkpoint-2500/special_tokens_map.json\nDeleting older checkpoint [model_checkpoint/checkpoint-1000] due to args.save_total_limit\nSaving model checkpoint to model_checkpoint/checkpoint-3000\nConfiguration saved in model_checkpoint/checkpoint-3000/config.json\nConfiguration saved in model_checkpoint/checkpoint-3000/generation_config.json\nModel weights saved in model_checkpoint/checkpoint-3000/pytorch_model.bin\ntokenizer config file saved in model_checkpoint/checkpoint-3000/tokenizer_config.json\nSpecial tokens file saved in model_checkpoint/checkpoint-3000/special_tokens_map.json\nDeleting older checkpoint [model_checkpoint/checkpoint-1500] due to args.save_total_limit\nSaving model checkpoint to model_checkpoint/checkpoint-3500\nConfiguration saved in model_checkpoint/checkpoint-3500/config.json\nConfiguration saved in model_checkpoint/checkpoint-3500/generation_config.json\nModel weights saved in model_checkpoint/checkpoint-3500/pytorch_model.bin\ntokenizer config file saved in model_checkpoint/checkpoint-3500/tokenizer_config.json\nSpecial tokens file saved in model_checkpoint/checkpoint-3500/special_tokens_map.json\nDeleting older checkpoint [model_checkpoint/checkpoint-2000] due to args.save_total_limit\nSaving model checkpoint to model_checkpoint/checkpoint-4000\nConfiguration saved in model_checkpoint/checkpoint-4000/config.json\nConfiguration saved in model_checkpoint/checkpoint-4000/generation_config.json\nModel weights saved in model_checkpoint/checkpoint-4000/pytorch_model.bin\ntokenizer config file saved in model_checkpoint/checkpoint-4000/tokenizer_config.json\nSpecial tokens file saved in model_checkpoint/checkpoint-4000/special_tokens_map.json\nDeleting older checkpoint [model_checkpoint/checkpoint-2500] due to args.save_total_limit\nSaving model checkpoint to model_checkpoint/checkpoint-4500\nConfiguration saved in model_checkpoint/checkpoint-4500/config.json\nConfiguration saved in model_checkpoint/checkpoint-4500/generation_config.json\nModel weights saved in model_checkpoint/checkpoint-4500/pytorch_model.bin\ntokenizer config file saved in model_checkpoint/checkpoint-4500/tokenizer_config.json\nSpecial tokens file saved in model_checkpoint/checkpoint-4500/special_tokens_map.json\nDeleting older checkpoint [model_checkpoint/checkpoint-3000] due to args.save_total_limit\nSaving model checkpoint to model_checkpoint/checkpoint-5000\nConfiguration saved in model_checkpoint/checkpoint-5000/config.json\nConfiguration saved in model_checkpoint/checkpoint-5000/generation_config.json\nModel weights saved in model_checkpoint/checkpoint-5000/pytorch_model.bin\ntokenizer config file saved in model_checkpoint/checkpoint-5000/tokenizer_config.json\nSpecial tokens file saved in model_checkpoint/checkpoint-5000/special_tokens_map.json\nDeleting older checkpoint [model_checkpoint/checkpoint-3500] due to args.save_total_limit\nSaving model checkpoint to model_checkpoint/checkpoint-5500\nConfiguration saved in model_checkpoint/checkpoint-5500/config.json\nConfiguration saved in model_checkpoint/checkpoint-5500/generation_config.json\nModel weights saved in model_checkpoint/checkpoint-5500/pytorch_model.bin\ntokenizer config file saved in model_checkpoint/checkpoint-5500/tokenizer_config.json\nSpecial tokens file saved in model_checkpoint/checkpoint-5500/special_tokens_map.json\nDeleting older checkpoint [model_checkpoint/checkpoint-4000] due to args.save_total_limit\nSaving model checkpoint to model_checkpoint/checkpoint-6000\nConfiguration saved in model_checkpoint/checkpoint-6000/config.json\nConfiguration saved in model_checkpoint/checkpoint-6000/generation_config.json\nModel weights saved in model_checkpoint/checkpoint-6000/pytorch_model.bin\ntokenizer config file saved in model_checkpoint/checkpoint-6000/tokenizer_config.json\nSpecial tokens file saved in model_checkpoint/checkpoint-6000/special_tokens_map.json\nDeleting older checkpoint [model_checkpoint/checkpoint-4500] due to args.save_total_limit\n\n\nTraining completed. Do not forget to share your model on huggingface.co/models =)\n\n\n","output_type":"stream"},{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=6250, training_loss=0.5581571008300781, metrics={'train_runtime': 1658.8493, 'train_samples_per_second': 241.131, 'train_steps_per_second': 3.768, 'total_flos': 4131498819059712.0, 'train_loss': 0.5581571008300781, 'epoch': 5.0})"},"metadata":{}}]},{"cell_type":"markdown","source":"## Using the Model","metadata":{}},{"cell_type":"code","source":"from transformers import pipeline\n\nmodel_checkpoint = \"/kaggle/working/model_checkpoint/checkpoint-6000\"","metadata":{"execution":{"iopub.status.busy":"2023-03-08T09:50:16.600183Z","iopub.execute_input":"2023-03-08T09:50:16.600906Z","iopub.status.idle":"2023-03-08T09:50:16.606815Z","shell.execute_reply.started":"2023-03-08T09:50:16.600851Z","shell.execute_reply":"2023-03-08T09:50:16.605589Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"def translate_text(text):\n    \n    translator = pipeline('translation', model = model_checkpoint)\n    translated_text = translator(text)[0]['translation_text']\n    \n    return translated_text","metadata":{"execution":{"iopub.status.busy":"2023-03-08T09:50:17.712806Z","iopub.execute_input":"2023-03-08T09:50:17.713487Z","iopub.status.idle":"2023-03-08T09:50:17.718799Z","shell.execute_reply.started":"2023-03-08T09:50:17.713453Z","shell.execute_reply":"2023-03-08T09:50:17.717743Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"translate_text('Akorede is my middle name.')","metadata":{"execution":{"iopub.status.busy":"2023-03-08T09:50:18.925794Z","iopub.execute_input":"2023-03-08T09:50:18.926499Z","iopub.status.idle":"2023-03-08T09:50:22.706045Z","shell.execute_reply.started":"2023-03-08T09:50:18.926461Z","shell.execute_reply":"2023-03-08T09:50:22.704924Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stderr","text":"loading configuration file /kaggle/working/model_checkpoint/checkpoint-6000/config.json\nModel config MarianConfig {\n  \"_name_or_path\": \"/kaggle/working/model_checkpoint/checkpoint-6000\",\n  \"_num_labels\": 3,\n  \"activation_dropout\": 0.0,\n  \"activation_function\": \"swish\",\n  \"add_bias_logits\": false,\n  \"add_final_layer_norm\": false,\n  \"architectures\": [\n    \"MarianMTModel\"\n  ],\n  \"attention_dropout\": 0.0,\n  \"bad_words_ids\": [\n    [\n      59513\n    ]\n  ],\n  \"bos_token_id\": 0,\n  \"classif_dropout\": 0.0,\n  \"classifier_dropout\": 0.0,\n  \"d_model\": 512,\n  \"decoder_attention_heads\": 8,\n  \"decoder_ffn_dim\": 2048,\n  \"decoder_layerdrop\": 0.0,\n  \"decoder_layers\": 6,\n  \"decoder_start_token_id\": 59513,\n  \"decoder_vocab_size\": 59514,\n  \"dropout\": 0.1,\n  \"encoder_attention_heads\": 8,\n  \"encoder_ffn_dim\": 2048,\n  \"encoder_layerdrop\": 0.0,\n  \"encoder_layers\": 6,\n  \"eos_token_id\": 0,\n  \"forced_eos_token_id\": 0,\n  \"gradient_checkpointing\": false,\n  \"id2label\": {\n    \"0\": \"LABEL_0\",\n    \"1\": \"LABEL_1\",\n    \"2\": \"LABEL_2\"\n  },\n  \"init_std\": 0.02,\n  \"is_encoder_decoder\": true,\n  \"label2id\": {\n    \"LABEL_0\": 0,\n    \"LABEL_1\": 1,\n    \"LABEL_2\": 2\n  },\n  \"max_length\": 512,\n  \"max_position_embeddings\": 512,\n  \"model_type\": \"marian\",\n  \"normalize_before\": false,\n  \"normalize_embedding\": false,\n  \"num_beams\": 4,\n  \"num_hidden_layers\": 6,\n  \"pad_token_id\": 59513,\n  \"scale_embedding\": true,\n  \"share_encoder_decoder_embeddings\": true,\n  \"static_position_embeddings\": true,\n  \"torch_dtype\": \"float32\",\n  \"transformers_version\": \"4.26.1\",\n  \"use_cache\": true,\n  \"vocab_size\": 59514\n}\n\nloading configuration file /kaggle/working/model_checkpoint/checkpoint-6000/config.json\nModel config MarianConfig {\n  \"_name_or_path\": \"/kaggle/working/model_checkpoint/checkpoint-6000\",\n  \"_num_labels\": 3,\n  \"activation_dropout\": 0.0,\n  \"activation_function\": \"swish\",\n  \"add_bias_logits\": false,\n  \"add_final_layer_norm\": false,\n  \"architectures\": [\n    \"MarianMTModel\"\n  ],\n  \"attention_dropout\": 0.0,\n  \"bad_words_ids\": [\n    [\n      59513\n    ]\n  ],\n  \"bos_token_id\": 0,\n  \"classif_dropout\": 0.0,\n  \"classifier_dropout\": 0.0,\n  \"d_model\": 512,\n  \"decoder_attention_heads\": 8,\n  \"decoder_ffn_dim\": 2048,\n  \"decoder_layerdrop\": 0.0,\n  \"decoder_layers\": 6,\n  \"decoder_start_token_id\": 59513,\n  \"decoder_vocab_size\": 59514,\n  \"dropout\": 0.1,\n  \"encoder_attention_heads\": 8,\n  \"encoder_ffn_dim\": 2048,\n  \"encoder_layerdrop\": 0.0,\n  \"encoder_layers\": 6,\n  \"eos_token_id\": 0,\n  \"forced_eos_token_id\": 0,\n  \"gradient_checkpointing\": false,\n  \"id2label\": {\n    \"0\": \"LABEL_0\",\n    \"1\": \"LABEL_1\",\n    \"2\": \"LABEL_2\"\n  },\n  \"init_std\": 0.02,\n  \"is_encoder_decoder\": true,\n  \"label2id\": {\n    \"LABEL_0\": 0,\n    \"LABEL_1\": 1,\n    \"LABEL_2\": 2\n  },\n  \"max_length\": 512,\n  \"max_position_embeddings\": 512,\n  \"model_type\": \"marian\",\n  \"normalize_before\": false,\n  \"normalize_embedding\": false,\n  \"num_beams\": 4,\n  \"num_hidden_layers\": 6,\n  \"pad_token_id\": 59513,\n  \"scale_embedding\": true,\n  \"share_encoder_decoder_embeddings\": true,\n  \"static_position_embeddings\": true,\n  \"torch_dtype\": \"float32\",\n  \"transformers_version\": \"4.26.1\",\n  \"use_cache\": true,\n  \"vocab_size\": 59514\n}\n\nloading weights file /kaggle/working/model_checkpoint/checkpoint-6000/pytorch_model.bin\nGenerate config GenerationConfig {\n  \"bad_words_ids\": [\n    [\n      59513\n    ]\n  ],\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 59513,\n  \"eos_token_id\": 0,\n  \"forced_eos_token_id\": 0,\n  \"max_length\": 512,\n  \"num_beams\": 4,\n  \"pad_token_id\": 59513,\n  \"transformers_version\": \"4.26.1\"\n}\n\nAll model checkpoint weights were used when initializing MarianMTModel.\n\nAll the weights of MarianMTModel were initialized from the model checkpoint at /kaggle/working/model_checkpoint/checkpoint-6000.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use MarianMTModel for predictions without further training.\nloading configuration file /kaggle/working/model_checkpoint/checkpoint-6000/generation_config.json\nGenerate config GenerationConfig {\n  \"_from_model_config\": true,\n  \"bad_words_ids\": [\n    [\n      59513\n    ]\n  ],\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 59513,\n  \"eos_token_id\": 0,\n  \"forced_eos_token_id\": 0,\n  \"max_length\": 512,\n  \"num_beams\": 4,\n  \"pad_token_id\": 59513,\n  \"transformers_version\": \"4.26.1\"\n}\n\nloading file source.spm\nloading file target.spm\nloading file vocab.json\nloading file target_vocab.json\nloading file tokenizer_config.json\nloading file added_tokens.json\nloading file special_tokens_map.json\nGenerate config GenerationConfig {\n  \"bad_words_ids\": [\n    [\n      59513\n    ]\n  ],\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 59513,\n  \"eos_token_id\": 0,\n  \"forced_eos_token_id\": 0,\n  \"max_length\": 512,\n  \"num_beams\": 4,\n  \"pad_token_id\": 59513,\n  \"transformers_version\": \"4.26.1\"\n}\n\n","output_type":"stream"},{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"'Akodede est mon second prénom.'"},"metadata":{}}]},{"cell_type":"code","source":"translate_text(\"I love to eat banana and mango.\")","metadata":{"execution":{"iopub.status.busy":"2023-03-08T09:50:29.900837Z","iopub.execute_input":"2023-03-08T09:50:29.901895Z","iopub.status.idle":"2023-03-08T09:50:33.686049Z","shell.execute_reply.started":"2023-03-08T09:50:29.901834Z","shell.execute_reply":"2023-03-08T09:50:33.684927Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stderr","text":"loading configuration file /kaggle/working/model_checkpoint/checkpoint-6000/config.json\nModel config MarianConfig {\n  \"_name_or_path\": \"/kaggle/working/model_checkpoint/checkpoint-6000\",\n  \"_num_labels\": 3,\n  \"activation_dropout\": 0.0,\n  \"activation_function\": \"swish\",\n  \"add_bias_logits\": false,\n  \"add_final_layer_norm\": false,\n  \"architectures\": [\n    \"MarianMTModel\"\n  ],\n  \"attention_dropout\": 0.0,\n  \"bad_words_ids\": [\n    [\n      59513\n    ]\n  ],\n  \"bos_token_id\": 0,\n  \"classif_dropout\": 0.0,\n  \"classifier_dropout\": 0.0,\n  \"d_model\": 512,\n  \"decoder_attention_heads\": 8,\n  \"decoder_ffn_dim\": 2048,\n  \"decoder_layerdrop\": 0.0,\n  \"decoder_layers\": 6,\n  \"decoder_start_token_id\": 59513,\n  \"decoder_vocab_size\": 59514,\n  \"dropout\": 0.1,\n  \"encoder_attention_heads\": 8,\n  \"encoder_ffn_dim\": 2048,\n  \"encoder_layerdrop\": 0.0,\n  \"encoder_layers\": 6,\n  \"eos_token_id\": 0,\n  \"forced_eos_token_id\": 0,\n  \"gradient_checkpointing\": false,\n  \"id2label\": {\n    \"0\": \"LABEL_0\",\n    \"1\": \"LABEL_1\",\n    \"2\": \"LABEL_2\"\n  },\n  \"init_std\": 0.02,\n  \"is_encoder_decoder\": true,\n  \"label2id\": {\n    \"LABEL_0\": 0,\n    \"LABEL_1\": 1,\n    \"LABEL_2\": 2\n  },\n  \"max_length\": 512,\n  \"max_position_embeddings\": 512,\n  \"model_type\": \"marian\",\n  \"normalize_before\": false,\n  \"normalize_embedding\": false,\n  \"num_beams\": 4,\n  \"num_hidden_layers\": 6,\n  \"pad_token_id\": 59513,\n  \"scale_embedding\": true,\n  \"share_encoder_decoder_embeddings\": true,\n  \"static_position_embeddings\": true,\n  \"torch_dtype\": \"float32\",\n  \"transformers_version\": \"4.26.1\",\n  \"use_cache\": true,\n  \"vocab_size\": 59514\n}\n\nloading configuration file /kaggle/working/model_checkpoint/checkpoint-6000/config.json\nModel config MarianConfig {\n  \"_name_or_path\": \"/kaggle/working/model_checkpoint/checkpoint-6000\",\n  \"_num_labels\": 3,\n  \"activation_dropout\": 0.0,\n  \"activation_function\": \"swish\",\n  \"add_bias_logits\": false,\n  \"add_final_layer_norm\": false,\n  \"architectures\": [\n    \"MarianMTModel\"\n  ],\n  \"attention_dropout\": 0.0,\n  \"bad_words_ids\": [\n    [\n      59513\n    ]\n  ],\n  \"bos_token_id\": 0,\n  \"classif_dropout\": 0.0,\n  \"classifier_dropout\": 0.0,\n  \"d_model\": 512,\n  \"decoder_attention_heads\": 8,\n  \"decoder_ffn_dim\": 2048,\n  \"decoder_layerdrop\": 0.0,\n  \"decoder_layers\": 6,\n  \"decoder_start_token_id\": 59513,\n  \"decoder_vocab_size\": 59514,\n  \"dropout\": 0.1,\n  \"encoder_attention_heads\": 8,\n  \"encoder_ffn_dim\": 2048,\n  \"encoder_layerdrop\": 0.0,\n  \"encoder_layers\": 6,\n  \"eos_token_id\": 0,\n  \"forced_eos_token_id\": 0,\n  \"gradient_checkpointing\": false,\n  \"id2label\": {\n    \"0\": \"LABEL_0\",\n    \"1\": \"LABEL_1\",\n    \"2\": \"LABEL_2\"\n  },\n  \"init_std\": 0.02,\n  \"is_encoder_decoder\": true,\n  \"label2id\": {\n    \"LABEL_0\": 0,\n    \"LABEL_1\": 1,\n    \"LABEL_2\": 2\n  },\n  \"max_length\": 512,\n  \"max_position_embeddings\": 512,\n  \"model_type\": \"marian\",\n  \"normalize_before\": false,\n  \"normalize_embedding\": false,\n  \"num_beams\": 4,\n  \"num_hidden_layers\": 6,\n  \"pad_token_id\": 59513,\n  \"scale_embedding\": true,\n  \"share_encoder_decoder_embeddings\": true,\n  \"static_position_embeddings\": true,\n  \"torch_dtype\": \"float32\",\n  \"transformers_version\": \"4.26.1\",\n  \"use_cache\": true,\n  \"vocab_size\": 59514\n}\n\nloading weights file /kaggle/working/model_checkpoint/checkpoint-6000/pytorch_model.bin\nGenerate config GenerationConfig {\n  \"bad_words_ids\": [\n    [\n      59513\n    ]\n  ],\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 59513,\n  \"eos_token_id\": 0,\n  \"forced_eos_token_id\": 0,\n  \"max_length\": 512,\n  \"num_beams\": 4,\n  \"pad_token_id\": 59513,\n  \"transformers_version\": \"4.26.1\"\n}\n\nAll model checkpoint weights were used when initializing MarianMTModel.\n\nAll the weights of MarianMTModel were initialized from the model checkpoint at /kaggle/working/model_checkpoint/checkpoint-6000.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use MarianMTModel for predictions without further training.\nloading configuration file /kaggle/working/model_checkpoint/checkpoint-6000/generation_config.json\nGenerate config GenerationConfig {\n  \"_from_model_config\": true,\n  \"bad_words_ids\": [\n    [\n      59513\n    ]\n  ],\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 59513,\n  \"eos_token_id\": 0,\n  \"forced_eos_token_id\": 0,\n  \"max_length\": 512,\n  \"num_beams\": 4,\n  \"pad_token_id\": 59513,\n  \"transformers_version\": \"4.26.1\"\n}\n\nloading file source.spm\nloading file target.spm\nloading file vocab.json\nloading file target_vocab.json\nloading file tokenizer_config.json\nloading file added_tokens.json\nloading file special_tokens_map.json\nGenerate config GenerationConfig {\n  \"bad_words_ids\": [\n    [\n      59513\n    ]\n  ],\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 59513,\n  \"eos_token_id\": 0,\n  \"forced_eos_token_id\": 0,\n  \"max_length\": 512,\n  \"num_beams\": 4,\n  \"pad_token_id\": 59513,\n  \"transformers_version\": \"4.26.1\"\n}\n\n","output_type":"stream"},{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"\"J'adore manger de la banane et de la mangue.\""},"metadata":{}}]},{"cell_type":"code","source":"translate_text(\"This is not very special.\")","metadata":{"execution":{"iopub.status.busy":"2023-03-08T09:52:37.249764Z","iopub.execute_input":"2023-03-08T09:52:37.250434Z","iopub.status.idle":"2023-03-08T09:52:40.455359Z","shell.execute_reply.started":"2023-03-08T09:52:37.250398Z","shell.execute_reply":"2023-03-08T09:52:40.454204Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stderr","text":"loading configuration file /kaggle/working/model_checkpoint/checkpoint-6000/config.json\nModel config MarianConfig {\n  \"_name_or_path\": \"/kaggle/working/model_checkpoint/checkpoint-6000\",\n  \"_num_labels\": 3,\n  \"activation_dropout\": 0.0,\n  \"activation_function\": \"swish\",\n  \"add_bias_logits\": false,\n  \"add_final_layer_norm\": false,\n  \"architectures\": [\n    \"MarianMTModel\"\n  ],\n  \"attention_dropout\": 0.0,\n  \"bad_words_ids\": [\n    [\n      59513\n    ]\n  ],\n  \"bos_token_id\": 0,\n  \"classif_dropout\": 0.0,\n  \"classifier_dropout\": 0.0,\n  \"d_model\": 512,\n  \"decoder_attention_heads\": 8,\n  \"decoder_ffn_dim\": 2048,\n  \"decoder_layerdrop\": 0.0,\n  \"decoder_layers\": 6,\n  \"decoder_start_token_id\": 59513,\n  \"decoder_vocab_size\": 59514,\n  \"dropout\": 0.1,\n  \"encoder_attention_heads\": 8,\n  \"encoder_ffn_dim\": 2048,\n  \"encoder_layerdrop\": 0.0,\n  \"encoder_layers\": 6,\n  \"eos_token_id\": 0,\n  \"forced_eos_token_id\": 0,\n  \"gradient_checkpointing\": false,\n  \"id2label\": {\n    \"0\": \"LABEL_0\",\n    \"1\": \"LABEL_1\",\n    \"2\": \"LABEL_2\"\n  },\n  \"init_std\": 0.02,\n  \"is_encoder_decoder\": true,\n  \"label2id\": {\n    \"LABEL_0\": 0,\n    \"LABEL_1\": 1,\n    \"LABEL_2\": 2\n  },\n  \"max_length\": 512,\n  \"max_position_embeddings\": 512,\n  \"model_type\": \"marian\",\n  \"normalize_before\": false,\n  \"normalize_embedding\": false,\n  \"num_beams\": 4,\n  \"num_hidden_layers\": 6,\n  \"pad_token_id\": 59513,\n  \"scale_embedding\": true,\n  \"share_encoder_decoder_embeddings\": true,\n  \"static_position_embeddings\": true,\n  \"torch_dtype\": \"float32\",\n  \"transformers_version\": \"4.26.1\",\n  \"use_cache\": true,\n  \"vocab_size\": 59514\n}\n\nloading configuration file /kaggle/working/model_checkpoint/checkpoint-6000/config.json\nModel config MarianConfig {\n  \"_name_or_path\": \"/kaggle/working/model_checkpoint/checkpoint-6000\",\n  \"_num_labels\": 3,\n  \"activation_dropout\": 0.0,\n  \"activation_function\": \"swish\",\n  \"add_bias_logits\": false,\n  \"add_final_layer_norm\": false,\n  \"architectures\": [\n    \"MarianMTModel\"\n  ],\n  \"attention_dropout\": 0.0,\n  \"bad_words_ids\": [\n    [\n      59513\n    ]\n  ],\n  \"bos_token_id\": 0,\n  \"classif_dropout\": 0.0,\n  \"classifier_dropout\": 0.0,\n  \"d_model\": 512,\n  \"decoder_attention_heads\": 8,\n  \"decoder_ffn_dim\": 2048,\n  \"decoder_layerdrop\": 0.0,\n  \"decoder_layers\": 6,\n  \"decoder_start_token_id\": 59513,\n  \"decoder_vocab_size\": 59514,\n  \"dropout\": 0.1,\n  \"encoder_attention_heads\": 8,\n  \"encoder_ffn_dim\": 2048,\n  \"encoder_layerdrop\": 0.0,\n  \"encoder_layers\": 6,\n  \"eos_token_id\": 0,\n  \"forced_eos_token_id\": 0,\n  \"gradient_checkpointing\": false,\n  \"id2label\": {\n    \"0\": \"LABEL_0\",\n    \"1\": \"LABEL_1\",\n    \"2\": \"LABEL_2\"\n  },\n  \"init_std\": 0.02,\n  \"is_encoder_decoder\": true,\n  \"label2id\": {\n    \"LABEL_0\": 0,\n    \"LABEL_1\": 1,\n    \"LABEL_2\": 2\n  },\n  \"max_length\": 512,\n  \"max_position_embeddings\": 512,\n  \"model_type\": \"marian\",\n  \"normalize_before\": false,\n  \"normalize_embedding\": false,\n  \"num_beams\": 4,\n  \"num_hidden_layers\": 6,\n  \"pad_token_id\": 59513,\n  \"scale_embedding\": true,\n  \"share_encoder_decoder_embeddings\": true,\n  \"static_position_embeddings\": true,\n  \"torch_dtype\": \"float32\",\n  \"transformers_version\": \"4.26.1\",\n  \"use_cache\": true,\n  \"vocab_size\": 59514\n}\n\nloading weights file /kaggle/working/model_checkpoint/checkpoint-6000/pytorch_model.bin\nGenerate config GenerationConfig {\n  \"bad_words_ids\": [\n    [\n      59513\n    ]\n  ],\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 59513,\n  \"eos_token_id\": 0,\n  \"forced_eos_token_id\": 0,\n  \"max_length\": 512,\n  \"num_beams\": 4,\n  \"pad_token_id\": 59513,\n  \"transformers_version\": \"4.26.1\"\n}\n\nAll model checkpoint weights were used when initializing MarianMTModel.\n\nAll the weights of MarianMTModel were initialized from the model checkpoint at /kaggle/working/model_checkpoint/checkpoint-6000.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use MarianMTModel for predictions without further training.\nloading configuration file /kaggle/working/model_checkpoint/checkpoint-6000/generation_config.json\nGenerate config GenerationConfig {\n  \"_from_model_config\": true,\n  \"bad_words_ids\": [\n    [\n      59513\n    ]\n  ],\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 59513,\n  \"eos_token_id\": 0,\n  \"forced_eos_token_id\": 0,\n  \"max_length\": 512,\n  \"num_beams\": 4,\n  \"pad_token_id\": 59513,\n  \"transformers_version\": \"4.26.1\"\n}\n\nloading file source.spm\nloading file target.spm\nloading file vocab.json\nloading file target_vocab.json\nloading file tokenizer_config.json\nloading file added_tokens.json\nloading file special_tokens_map.json\nGenerate config GenerationConfig {\n  \"bad_words_ids\": [\n    [\n      59513\n    ]\n  ],\n  \"bos_token_id\": 0,\n  \"decoder_start_token_id\": 59513,\n  \"eos_token_id\": 0,\n  \"forced_eos_token_id\": 0,\n  \"max_length\": 512,\n  \"num_beams\": 4,\n  \"pad_token_id\": 59513,\n  \"transformers_version\": \"4.26.1\"\n}\n\n","output_type":"stream"},{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"\"Ce n'est pas très spécial.\""},"metadata":{}}]},{"cell_type":"markdown","source":"### Resources\n\n[HuggingFace](https://github.com/huggingface/notebooks/blob/main/examples/translation.ipynb)\n[HuggingFace](https://huggingface.co/course/chapter7/4?fw=tf#processing-the-data)","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}