{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"In this notebook, we use the Simple Books dataset to pretrain a transformer with the task of causal language modelling. We have understood the two pretraining objectives we have for this kind of task - the causal language modelling and the masked language modelling. The causal language modelling is the autoregressive objective in which the neural network learns to predict the next token given a set of previous tokens in the sequence. In masked language modelling, the objective is to predict the masked token given the context of surrounding tokens.\n\nFor a high level understanding of the text-generation task and the pretraining objective, [the introductory notebook](https://github.com/Akorex/Natural-Language-Processing/blob/main/Text%20Generation/introduction-to-text-generation.ipynb) is quite useful.","metadata":{}},{"cell_type":"markdown","source":"## Preparing the Environment","metadata":{"id":"HElYL4Kc0ZCX"}},{"cell_type":"code","source":"import os\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom datasets import load_dataset\n\n# Train in mixed-precision float16\ntf.keras.mixed_precision.set_global_policy(\"mixed_float16\")","metadata":{"id":"mY4WI8oN0ZCX","executionInfo":{"status":"ok","timestamp":1682268916152,"user_tz":-60,"elapsed":4060,"user":{"displayName":"Akorede Adewole","userId":"16474677199734761810"}},"execution":{"iopub.status.busy":"2023-09-08T20:57:20.330701Z","iopub.execute_input":"2023-09-08T20:57:20.331353Z","iopub.status.idle":"2023-09-08T20:57:32.125323Z","shell.execute_reply.started":"2023-09-08T20:57:20.331306Z","shell.execute_reply":"2023-09-08T20:57:32.124152Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# set up multi-GPU/TPU use\ntry:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect()\n    strategy = tf.distribute.TPUStrategy(tpu)\nexcept ValueError:\n    strategy = tf.distribute.MirroredStrategy()\nprint('Number of devices: {}'.format(strategy.num_replicas_in_sync))","metadata":{"execution":{"iopub.status.busy":"2023-09-08T20:57:32.127743Z","iopub.execute_input":"2023-09-08T20:57:32.128969Z","iopub.status.idle":"2023-09-08T20:57:36.111430Z","shell.execute_reply.started":"2023-09-08T20:57:32.128922Z","shell.execute_reply":"2023-09-08T20:57:36.110236Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Number of devices: 2\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Some Hyperparameters","metadata":{"id":"Sq314qge0ZCZ"}},{"cell_type":"code","source":"# dataset\nBATCH_SIZE = 64\nBUFFER_SIZE = 256\nSEQ_LEN = 128\nMIN_TRAINING_SEQ_LEN = 450","metadata":{"id":"E9tNkYIF0ZCZ","executionInfo":{"status":"ok","timestamp":1682268919020,"user_tz":-60,"elapsed":11,"user":{"displayName":"Akorede Adewole","userId":"16474677199734761810"}},"execution":{"iopub.status.busy":"2023-09-08T20:57:36.113134Z","iopub.execute_input":"2023-09-08T20:57:36.113540Z","iopub.status.idle":"2023-09-08T20:57:36.119439Z","shell.execute_reply.started":"2023-09-08T20:57:36.113499Z","shell.execute_reply":"2023-09-08T20:57:36.117923Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"## 1.0 The Dataset","metadata":{"id":"EmGwku2t0ZCa"}},{"cell_type":"markdown","source":"The dataset we'll use is the SimpleBooks dataset. The SimpleBooks dataset consists of 1,573 Gutenberg books, and has one of the smallest vocabulary size to word-level tokens ratio. It has a vocabulary size of approx 98k, a third of WikiText-103's, with around the same number of tokens (approx 100M). This makes it easy to fit a small model.","metadata":{"id":"bYZXWnnA0ZCa"}},{"cell_type":"markdown","source":"We download the dataset using the Keras utility code and load them in HuggingFace Datasets object. This is the approach we'll use in this notebook.","metadata":{"id":"Ck_0Douw0ZCa"}},{"cell_type":"code","source":"keras.utils.get_file(\n    origin=\"https://dldata-public.s3.us-east-2.amazonaws.com/simplebooks.zip\",\n    extract=True,\n)\ndir = os.path.expanduser(\"~/.keras/datasets/simplebooks/\")\n\ntrain_path = dir + \"simplebooks-92-raw/train.txt\"\nval_path = dir + \"simplebooks-92-raw/valid.txt\"","metadata":{"id":"FtH1f0aO0ZCa","executionInfo":{"status":"ok","timestamp":1682268934898,"user_tz":-60,"elapsed":15888,"user":{"displayName":"Akorede Adewole","userId":"16474677199734761810"}},"outputId":"07ecef22-63da-4ad9-99d7-561875c76dbd","execution":{"iopub.status.busy":"2023-09-08T20:57:36.123052Z","iopub.execute_input":"2023-09-08T20:57:36.123574Z","iopub.status.idle":"2023-09-08T20:57:49.889910Z","shell.execute_reply.started":"2023-09-08T20:57:36.123534Z","shell.execute_reply":"2023-09-08T20:57:49.888758Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Downloading data from https://dldata-public.s3.us-east-2.amazonaws.com/simplebooks.zip\n282386239/282386239 [==============================] - 7s 0us/step\n","output_type":"stream"}]},{"cell_type":"code","source":"raw_train_ds = load_dataset('text', data_files = train_path)\n\nraw_val_ds = load_dataset('text', data_files = val_path)","metadata":{"id":"FlP8UZx_0ZCb","executionInfo":{"status":"ok","timestamp":1682268945962,"user_tz":-60,"elapsed":11077,"user":{"displayName":"Akorede Adewole","userId":"16474677199734761810"}},"outputId":"87acc06e-fa8b-4154-f57c-5e24f4884ba4","execution":{"iopub.status.busy":"2023-09-08T20:57:49.891396Z","iopub.execute_input":"2023-09-08T20:57:49.892454Z","iopub.status.idle":"2023-09-08T20:57:56.708399Z","shell.execute_reply.started":"2023-09-08T20:57:49.892408Z","shell.execute_reply":"2023-09-08T20:57:56.707182Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Downloading and preparing dataset text/default to /root/.cache/huggingface/datasets/text/default-19fb8885f73698bd/0.0.0/4b86d314f7236db91f0a0f5cda32d4375445e64c5eda2692655dd99c2dac68e8...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"080e4c47e23549c0b83fc98ee551e11d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"74f4d3b7dc8840ecb234ad0362c61f5e"}},"metadata":{}},{"name":"stdout","text":"Dataset text downloaded and prepared to /root/.cache/huggingface/datasets/text/default-19fb8885f73698bd/0.0.0/4b86d314f7236db91f0a0f5cda32d4375445e64c5eda2692655dd99c2dac68e8. Subsequent calls will reuse this data.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"28401173e384449cbe76e6ce96becfbe"}},"metadata":{}},{"name":"stdout","text":"Downloading and preparing dataset text/default to /root/.cache/huggingface/datasets/text/default-f7c4c38fd0f348e3/0.0.0/4b86d314f7236db91f0a0f5cda32d4375445e64c5eda2692655dd99c2dac68e8...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"26177eeed30742e681f990f2bfb4aa8f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d003b7b4ffe947e880338dd71cec9ddb"}},"metadata":{}},{"name":"stdout","text":"Dataset text downloaded and prepared to /root/.cache/huggingface/datasets/text/default-f7c4c38fd0f348e3/0.0.0/4b86d314f7236db91f0a0f5cda32d4375445e64c5eda2692655dd99c2dac68e8. Subsequent calls will reuse this data.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"33b223cec88c4516ad9b7d58819c3f0f"}},"metadata":{}}]},{"cell_type":"code","source":"print(raw_train_ds)\nprint(\"\\n\")\nprint(raw_val_ds)","metadata":{"id":"GdrrCZWZ0ZCb","executionInfo":{"status":"ok","timestamp":1682268945963,"user_tz":-60,"elapsed":8,"user":{"displayName":"Akorede Adewole","userId":"16474677199734761810"}},"outputId":"33ba71de-0d81-448e-95c3-1d4b583f186f","execution":{"iopub.status.busy":"2023-09-08T20:57:56.710466Z","iopub.execute_input":"2023-09-08T20:57:56.711194Z","iopub.status.idle":"2023-09-08T20:57:56.717335Z","shell.execute_reply.started":"2023-09-08T20:57:56.711153Z","shell.execute_reply":"2023-09-08T20:57:56.716281Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"DatasetDict({\n    train: Dataset({\n        features: ['text'],\n        num_rows: 3876796\n    })\n})\n\n\nDatasetDict({\n    train: Dataset({\n        features: ['text'],\n        num_rows: 13384\n    })\n})\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Let us write a function in python using keras tool to load the dataset in a similar way as implemented above.","metadata":{"id":"mtctMnIy0ZCb"}},{"cell_type":"code","source":"def load_dataset_tf():\n    \"\"\"Utility to load the dataset into TensorFlow TF Data object.\n    \n    This is a more suitable approach when using the TensorFlow/Keras libraries\n    \"\"\"\n    \n    # download the file\n    keras.utils.get_file(\n    origin=\"https://dldata-public.s3.us-east-2.amazonaws.com/simplebooks.zip\",\n    extract=True)\n    \n    # set the path\n    dir = os.path.expanduser(\"~/.keras/datasets/simplebooks/\")\n    train_path = dir + \"simplebooks-92-raw/train.txt\"\n    val_path = dir + \"simplebooks-92-raw/valid.txt\"\n    \n    raw_train_ds = (\n        tf.data.TextLineDataset(train_path)\n        .filter(lambda x: tf.strings.length(x) > MIN_TRAINING_SEQ_LEN)\n        .batch(BATCH_SIZE)\n        .shuffle(buffer_size=BUFFER_SIZE)\n    )\n    \n    raw_val_ds = (\n        tf.data.TextLineDataset(dir + \"simplebooks-92-raw/valid.txt\")\n        .filter(lambda x: tf.strings.length(x) > MIN_TRAINING_SEQ_LEN)\n        .batch(BATCH_SIZE)\n    )\n    \n    print(raw_train_ds.unbatch().batch(1).take(1).get_single_element())\n    print(raw_val_ds.unbatch().batch(1).take(1).get_single_element())","metadata":{"id":"db5ykk9b0ZCb","executionInfo":{"status":"ok","timestamp":1682268945964,"user_tz":-60,"elapsed":7,"user":{"displayName":"Akorede Adewole","userId":"16474677199734761810"}},"execution":{"iopub.status.busy":"2023-09-08T20:57:56.719020Z","iopub.execute_input":"2023-09-08T20:57:56.719747Z","iopub.status.idle":"2023-09-08T20:57:56.935032Z","shell.execute_reply.started":"2023-09-08T20:57:56.719708Z","shell.execute_reply":"2023-09-08T20:57:56.933850Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"## 2.0 Tokenization","metadata":{"id":"19RHOZ8M0ZCc"}},{"cell_type":"code","source":"from transformers import AutoTokenizer\n\ntokenizer = AutoTokenizer.from_pretrained('gpt2')","metadata":{"id":"JSwAf6Oe0ZCc","executionInfo":{"status":"ok","timestamp":1682268948389,"user_tz":-60,"elapsed":2431,"user":{"displayName":"Akorede Adewole","userId":"16474677199734761810"}},"outputId":"2ffadd3d-99e5-4577-ff17-82c56c36730f","execution":{"iopub.status.busy":"2023-09-08T20:57:56.936807Z","iopub.execute_input":"2023-09-08T20:57:56.937246Z","iopub.status.idle":"2023-09-08T20:57:59.974694Z","shell.execute_reply.started":"2023-09-08T20:57:56.937190Z","shell.execute_reply":"2023-09-08T20:57:59.972800Z"},"trusted":true},"execution_count":8,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading (…)lve/main/config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"21295c03ad904d0093beea0ac3631b1b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)olve/main/vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0f85b0b1f06842fcb8ab053080269fd4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"be45e59303bd4a7eb37156a886e91f56"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"695d0035a8704f42922974d74639138d"}},"metadata":{}}]},{"cell_type":"code","source":"# let's see some things about the tokenizer\nprint(f\"Vocab Size: {tokenizer.vocab_size}\")\nprint(f\"Model Input names: {tokenizer.model_input_names}\")\nprint(f\"Special tokens: {tokenizer.special_tokens_map}\")\nprint(f\"Model max seq length: {tokenizer.model_max_length}\")","metadata":{"id":"9q_jwC5V0ZCc","executionInfo":{"status":"ok","timestamp":1682268948389,"user_tz":-60,"elapsed":20,"user":{"displayName":"Akorede Adewole","userId":"16474677199734761810"}},"outputId":"ef317bc1-b7b3-4c23-a925-790a38fe996f","execution":{"iopub.status.busy":"2023-09-08T20:57:59.980573Z","iopub.execute_input":"2023-09-08T20:57:59.980995Z","iopub.status.idle":"2023-09-08T20:57:59.988535Z","shell.execute_reply.started":"2023-09-08T20:57:59.980952Z","shell.execute_reply":"2023-09-08T20:57:59.987389Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Vocab Size: 50257\nModel Input names: ['input_ids', 'attention_mask']\nSpecial tokens: {'bos_token': '<|endoftext|>', 'eos_token': '<|endoftext|>', 'unk_token': '<|endoftext|>'}\nModel max seq length: 1024\n","output_type":"stream"}]},{"cell_type":"code","source":"text = \"This is a sample text\"\n\ntokenizer(text, add_special_tokens = False)","metadata":{"id":"cz7sCMwq0ZCc","executionInfo":{"status":"ok","timestamp":1682268948390,"user_tz":-60,"elapsed":16,"user":{"displayName":"Akorede Adewole","userId":"16474677199734761810"}},"outputId":"b59d8dbc-4e03-4695-834f-e73ee04a89d6","execution":{"iopub.status.busy":"2023-09-08T20:57:59.995625Z","iopub.execute_input":"2023-09-08T20:57:59.996246Z","iopub.status.idle":"2023-09-08T20:58:01.096303Z","shell.execute_reply.started":"2023-09-08T20:57:59.996185Z","shell.execute_reply":"2023-09-08T20:58:01.091870Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"{'input_ids': [1212, 318, 257, 6291, 2420], 'attention_mask': [1, 1, 1, 1, 1]}"},"metadata":{}}]},{"cell_type":"code","source":"def tokenize(batch):\n    return tokenizer(batch['text'], truncation = True, max_length = SEQ_LEN)","metadata":{"id":"DwIGH59l0ZCd","executionInfo":{"status":"ok","timestamp":1682268948392,"user_tz":-60,"elapsed":12,"user":{"displayName":"Akorede Adewole","userId":"16474677199734761810"}},"execution":{"iopub.status.busy":"2023-09-08T20:58:01.099952Z","iopub.execute_input":"2023-09-08T20:58:01.100711Z","iopub.status.idle":"2023-09-08T20:58:01.235705Z","shell.execute_reply.started":"2023-09-08T20:58:01.100672Z","shell.execute_reply":"2023-09-08T20:58:01.224019Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"train_ds = raw_train_ds.map(tokenize, batched = True, remove_columns=raw_train_ds[\"train\"].column_names)\nval_ds = raw_val_ds.map(tokenize, batched = True, remove_columns = raw_val_ds['train'].column_names)","metadata":{"id":"0F49KsAE0ZCd","executionInfo":{"status":"ok","timestamp":1682269247195,"user_tz":-60,"elapsed":298814,"user":{"displayName":"Akorede Adewole","userId":"16474677199734761810"}},"outputId":"acea721d-2c27-4f31-fd89-c0fbeb0372c4","execution":{"iopub.status.busy":"2023-09-08T20:58:01.238077Z","iopub.execute_input":"2023-09-08T20:58:01.238481Z","iopub.status.idle":"2023-09-08T21:03:26.919080Z","shell.execute_reply.started":"2023-09-08T20:58:01.238444Z","shell.execute_reply":"2023-09-08T21:03:26.917989Z"},"trusted":true},"execution_count":12,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/3877 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f88899c9c65743ef8a58e5e23f4ee3c1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/14 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e0631319a62e4db29bd1ad9d05afb356"}},"metadata":{}}]},{"cell_type":"code","source":"print(train_ds)\nprint(\"\\n\")\nprint(val_ds)","metadata":{"id":"J3eC4QMa0ZCd","executionInfo":{"status":"ok","timestamp":1682269247196,"user_tz":-60,"elapsed":5,"user":{"displayName":"Akorede Adewole","userId":"16474677199734761810"}},"outputId":"30c83f1f-575b-46ed-85b0-02fefe1a4eed","execution":{"iopub.status.busy":"2023-09-08T21:03:26.920525Z","iopub.execute_input":"2023-09-08T21:03:26.922527Z","iopub.status.idle":"2023-09-08T21:03:26.929219Z","shell.execute_reply.started":"2023-09-08T21:03:26.922465Z","shell.execute_reply":"2023-09-08T21:03:26.927714Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"DatasetDict({\n    train: Dataset({\n        features: ['input_ids', 'attention_mask'],\n        num_rows: 3876796\n    })\n})\n\n\nDatasetDict({\n    train: Dataset({\n        features: ['input_ids', 'attention_mask'],\n        num_rows: 13384\n    })\n})\n","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import DataCollatorForLanguageModeling\n\ntokenizer.pad_token = tokenizer.eos_token\ndata_collator = DataCollatorForLanguageModeling(tokenizer, mlm=False, return_tensors=\"tf\")","metadata":{"id":"TigzQsxd0ZCd","executionInfo":{"status":"ok","timestamp":1682269251003,"user_tz":-60,"elapsed":3810,"user":{"displayName":"Akorede Adewole","userId":"16474677199734761810"}},"execution":{"iopub.status.busy":"2023-09-08T21:03:26.931096Z","iopub.execute_input":"2023-09-08T21:03:26.931842Z","iopub.status.idle":"2023-09-08T21:03:30.016687Z","shell.execute_reply.started":"2023-09-08T21:03:26.931802Z","shell.execute_reply":"2023-09-08T21:03:30.015593Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"## 3.0 Training the Model From Scratch","metadata":{"id":"SjudZRQE0ZCd"}},{"cell_type":"markdown","source":"For this task, we'll be using the causal language modelling objective. Let's load some items","metadata":{"id":"J466i7Cp0ZCe"}},{"cell_type":"code","source":"from transformers import AutoConfig, TFGPT2LMHeadModel\n\nconfig = AutoConfig.from_pretrained('gpt2', vocab_size=len(tokenizer), \n                                    bos_token_id=tokenizer.bos_token_id,eos_token_id=tokenizer.eos_token_id, n_ctx=SEQ_LEN)","metadata":{"id":"F5lPrtKx0ZCe","executionInfo":{"status":"ok","timestamp":1682269348718,"user_tz":-60,"elapsed":376,"user":{"displayName":"Akorede Adewole","userId":"16474677199734761810"}},"execution":{"iopub.status.busy":"2023-09-08T21:03:30.018256Z","iopub.execute_input":"2023-09-08T21:03:30.018619Z","iopub.status.idle":"2023-09-08T21:03:30.238940Z","shell.execute_reply.started":"2023-09-08T21:03:30.018580Z","shell.execute_reply":"2023-09-08T21:03:30.237909Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"config","metadata":{"execution":{"iopub.status.busy":"2023-09-08T21:03:30.240507Z","iopub.execute_input":"2023-09-08T21:03:30.241075Z","iopub.status.idle":"2023-09-08T21:03:30.251106Z","shell.execute_reply.started":"2023-09-08T21:03:30.241034Z","shell.execute_reply":"2023-09-08T21:03:30.249875Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"GPT2Config {\n  \"_name_or_path\": \"gpt2\",\n  \"activation_function\": \"gelu_new\",\n  \"architectures\": [\n    \"GPT2LMHeadModel\"\n  ],\n  \"attn_pdrop\": 0.1,\n  \"bos_token_id\": 50256,\n  \"embd_pdrop\": 0.1,\n  \"eos_token_id\": 50256,\n  \"initializer_range\": 0.02,\n  \"layer_norm_epsilon\": 1e-05,\n  \"model_type\": \"gpt2\",\n  \"n_ctx\": 128,\n  \"n_embd\": 768,\n  \"n_head\": 12,\n  \"n_inner\": null,\n  \"n_layer\": 12,\n  \"n_positions\": 1024,\n  \"reorder_and_upcast_attn\": false,\n  \"resid_pdrop\": 0.1,\n  \"scale_attn_by_inverse_layer_idx\": false,\n  \"scale_attn_weights\": true,\n  \"summary_activation\": null,\n  \"summary_first_dropout\": 0.1,\n  \"summary_proj_to_labels\": true,\n  \"summary_type\": \"cls_index\",\n  \"summary_use_proj\": true,\n  \"task_specific_params\": {\n    \"text-generation\": {\n      \"do_sample\": true,\n      \"max_length\": 50\n    }\n  },\n  \"transformers_version\": \"4.27.4\",\n  \"use_cache\": true,\n  \"vocab_size\": 50257\n}"},"metadata":{}}]},{"cell_type":"code","source":"with strategy.scope():\n    model = TFGPT2LMHeadModel(config)\n    model(model.dummy_inputs)  # Builds the model\n\nmodel.summary()","metadata":{"id":"nT0ABTxo0ZCe","executionInfo":{"status":"ok","timestamp":1682269352443,"user_tz":-60,"elapsed":2467,"user":{"displayName":"Akorede Adewole","userId":"16474677199734761810"}},"outputId":"89b42c97-e81f-4aaa-98e2-8b8984a43abc","execution":{"iopub.status.busy":"2023-09-08T21:03:30.252709Z","iopub.execute_input":"2023-09-08T21:03:30.254603Z","iopub.status.idle":"2023-09-08T21:03:37.247731Z","shell.execute_reply.started":"2023-09-08T21:03:30.254573Z","shell.execute_reply":"2023-09-08T21:03:37.246495Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"Model: \"tfgpt2lm_head_model\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n transformer (TFGPT2MainLaye  multiple                 124439808 \n r)                                                              \n                                                                 \n=================================================================\nTotal params: 124,439,808\nTrainable params: 124,439,808\nNon-trainable params: 0\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"with strategy.scope():\n    train_dataset = model.prepare_tf_dataset(\n        train_ds[\"train\"], collate_fn=data_collator,\n        shuffle=True,batch_size=32,)\n    \n    eval_dataset = model.prepare_tf_dataset(\n        val_ds[\"train\"],collate_fn=data_collator,\n        shuffle=False,batch_size=32,)","metadata":{"id":"o16M-iHa0ZCe","executionInfo":{"status":"ok","timestamp":1682269357636,"user_tz":-60,"elapsed":1735,"user":{"displayName":"Akorede Adewole","userId":"16474677199734761810"}},"execution":{"iopub.status.busy":"2023-09-08T21:03:37.249475Z","iopub.execute_input":"2023-09-08T21:03:37.249955Z","iopub.status.idle":"2023-09-08T21:03:37.750943Z","shell.execute_reply.started":"2023-09-08T21:03:37.249912Z","shell.execute_reply":"2023-09-08T21:03:37.749836Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stderr","text":"You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","output_type":"stream"}]},{"cell_type":"code","source":"save_path = 'transformer/'\ncallbacks = tf.keras.callbacks.ModelCheckpoint(save_path, save_best_only = False, save_freq = 5000)","metadata":{"id":"2ZXurofS0ZCe","executionInfo":{"status":"ok","timestamp":1682269484664,"user_tz":-60,"elapsed":397,"user":{"displayName":"Akorede Adewole","userId":"16474677199734761810"}},"execution":{"iopub.status.busy":"2023-09-08T21:03:37.752526Z","iopub.execute_input":"2023-09-08T21:03:37.752919Z","iopub.status.idle":"2023-09-08T21:03:37.758649Z","shell.execute_reply.started":"2023-09-08T21:03:37.752878Z","shell.execute_reply":"2023-09-08T21:03:37.757281Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"from transformers import create_optimizer\n\nwith strategy.scope():\n    num_train_steps = len(train_dataset)\n    optimizer, schedule = create_optimizer(\n        init_lr=5e-5,\n        num_warmup_steps=1_000,\n        num_train_steps=num_train_steps,\n        weight_decay_rate=0.01\n    )\n    \n    model.compile(optimizer=optimizer)\n","metadata":{"id":"3fuMYSSP0ZCf","executionInfo":{"status":"ok","timestamp":1682269485151,"user_tz":-60,"elapsed":2,"user":{"displayName":"Akorede Adewole","userId":"16474677199734761810"}},"outputId":"78ef71de-e147-4a48-fb1e-dc3303c5dd5b","execution":{"iopub.status.busy":"2023-09-08T21:03:37.760722Z","iopub.execute_input":"2023-09-08T21:03:37.761534Z","iopub.status.idle":"2023-09-08T21:03:37.814022Z","shell.execute_reply.started":"2023-09-08T21:03:37.761494Z","shell.execute_reply":"2023-09-08T21:03:37.813031Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stderr","text":"No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n","output_type":"stream"}]},{"cell_type":"code","source":"model.fit(train_dataset, validation_data=eval_dataset, callbacks=[callbacks], batch_size = BATCH_SIZE)","metadata":{"id":"-DB6qRFc0ZCf","executionInfo":{"status":"error","timestamp":1682270141951,"user_tz":-60,"elapsed":656293,"user":{"displayName":"Akorede Adewole","userId":"16474677199734761810"}},"outputId":"6c8dfba6-3a72-4cfc-ef4a-dddd8eb2af82","execution":{"iopub.status.busy":"2023-09-08T21:03:37.816308Z","iopub.execute_input":"2023-09-08T21:03:37.816998Z","iopub.status.idle":"2023-09-08T21:53:57.316312Z","shell.execute_reply.started":"2023-09-08T21:03:37.816961Z","shell.execute_reply":"2023-09-08T21:53:57.313528Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"  7170/121149 [>.............................] - ETA: 13:01:39 - loss: 5.6499","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_22/1214851011.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1648\u001b[0m                         ):\n\u001b[1;32m   1649\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1650\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1651\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1652\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    878\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    910\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 912\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    913\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    133\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m    134\u001b[0m     return concrete_function._call_flat(\n\u001b[0;32m--> 135\u001b[0;31m         filtered_flat_args, captured_inputs=concrete_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    381\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 383\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    384\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m           outputs = execute.execute_with_cancellation(\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 53\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     54\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"# save the config file\n\nconfig.to_json_file('transformer/config.json')","metadata":{"id":"YqaY3tR4_TOB","executionInfo":{"status":"ok","timestamp":1682270151003,"user_tz":-60,"elapsed":7,"user":{"displayName":"Akorede Adewole","userId":"16474677199734761810"}},"execution":{"iopub.status.busy":"2023-09-08T21:54:01.510621Z","iopub.execute_input":"2023-09-08T21:54:01.511272Z","iopub.status.idle":"2023-09-08T21:54:01.520460Z","shell.execute_reply.started":"2023-09-08T21:54:01.511224Z","shell.execute_reply":"2023-09-08T21:54:01.519406Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":"### Using the trained model","metadata":{"id":"tjTAoY240ZCf"}},{"cell_type":"code","source":"from transformers import pipeline\n\npipe = pipeline(\"text-generation\", model= model, tokenizer=tokenizer, device=0)","metadata":{"id":"xvlJXt2RHfHz","executionInfo":{"status":"error","timestamp":1682270191697,"user_tz":-60,"elapsed":1269,"user":{"displayName":"Akorede Adewole","userId":"16474677199734761810"}},"outputId":"4ba98f89-236c-4a23-f2ab-bdaf671d43ad","execution":{"iopub.status.busy":"2023-09-08T21:54:02.801722Z","iopub.execute_input":"2023-09-08T21:54:02.802103Z","iopub.status.idle":"2023-09-08T21:54:04.588427Z","shell.execute_reply.started":"2023-09-08T21:54:02.802067Z","shell.execute_reply":"2023-09-08T21:54:04.587340Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"text = \"Transformers are the most\"\nprint(pipe(text, num_return_sequences=1)[0][\"generated_text\"])","metadata":{"execution":{"iopub.status.busy":"2023-09-08T21:54:04.590778Z","iopub.execute_input":"2023-09-08T21:54:04.591160Z","iopub.status.idle":"2023-09-08T21:54:14.278763Z","shell.execute_reply.started":"2023-09-08T21:54:04.591122Z","shell.execute_reply":"2023-09-08T21:54:14.277509Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/transformers/generation/tf_utils.py:746: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation)\n  \"You have modified the pretrained model configuration to control generation. This is a\"\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n/opt/conda/lib/python3.7/site-packages/transformers/generation/tf_utils.py:858: UserWarning: Using `max_length`'s default (50) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n  UserWarning,\n","output_type":"stream"},{"name":"stdout","text":"Transformers are the most little answer. In this moment in the end had been heard of the first of the evening. There was a beautiful little young boy. \"Oh, my child, so, we can't do your little child.\" \"I\n","output_type":"stream"}]},{"cell_type":"code","source":"text = \"I believe in the power of \"\nprint(pipe(text, num_return_sequences=1)[0][\"generated_text\"])","metadata":{"execution":{"iopub.status.busy":"2023-09-08T21:54:14.280261Z","iopub.execute_input":"2023-09-08T21:54:14.280607Z","iopub.status.idle":"2023-09-08T21:54:23.936104Z","shell.execute_reply.started":"2023-09-08T21:54:14.280576Z","shell.execute_reply":"2023-09-08T21:54:23.934909Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"I believe in the power of  There was an end of the top of the ship, and, with the same great in the dark, which was a part of the wood, the three, they had gone in a tree without work, for I\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Resources","metadata":{"id":"2ns3c0w40ZCf"}},{"cell_type":"markdown","source":"1. [HuggingFace Load Text](https://huggingface.co/docs/datasets/nlp_load)\n2. [HuggingFace Load Datasets](https://huggingface.co/docs/datasets/dataset_script)\n3. [KerasNLP Word Generation](https://keras.io/examples/nlp/text_generation_gpt/)\n4. [Using Multiple GPUs](https://www.kaggle.com/code/gusthema/multigpu-with-tensorflow-and-keras)\n5. [HuggingFace course](https://huggingface.co/course/chapter7/6?fw=tf)","metadata":{"id":"nsHUc6Y30ZCf"}},{"cell_type":"code","source":"","metadata":{"id":"sEH3syI60ZCf"},"execution_count":null,"outputs":[]}]}