{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6eae7dd",
   "metadata": {
    "papermill": {
     "duration": 0.008186,
     "end_time": "2023-10-07T10:01:47.617306",
     "exception": false,
     "start_time": "2023-10-07T10:01:47.609120",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The idea of this notebook is to improve the score obtained from [Experiment 1](https://github.com/Akorex/Natural-Language-Processing/blob/main/Kaggle%20Competitions/commonlit-experiment-1.ipynb) and [the Baseline notebook](https://www.kaggle.com/code/adewoleakorede/baseline-submission) on the Kaggle board. Ideas in this notebook is majorly inspired by earlier work and this [Kaggle notebook](https://www.kaggle.com/code/siddhvr/commonlit-ess-lgbm-autocorrect-deberta-v3-tuned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9bd58d6d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-07T10:01:47.634672Z",
     "iopub.status.busy": "2023-10-07T10:01:47.634036Z",
     "iopub.status.idle": "2023-10-07T10:02:21.060743Z",
     "shell.execute_reply": "2023-10-07T10:02:21.059633Z"
    },
    "papermill": {
     "duration": 33.437943,
     "end_time": "2023-10-07T10:02:21.063024",
     "exception": false,
     "start_time": "2023-10-07T10:01:47.625081",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /kaggle/input/pyspellchecker/pyspellchecker-0.7.2-py3-none-any.whl\r\n",
      "Installing collected packages: pyspellchecker\r\n",
      "Successfully installed pyspellchecker-0.7.2\r\n"
     ]
    }
   ],
   "source": [
    "!pip install \"/kaggle/input/pyspellchecker/pyspellchecker-0.7.2-py3-none-any.whl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e46b17d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-07T10:02:21.080934Z",
     "iopub.status.busy": "2023-10-07T10:02:21.080420Z",
     "iopub.status.idle": "2023-10-07T10:02:27.019669Z",
     "shell.execute_reply": "2023-10-07T10:02:27.018724Z"
    },
    "papermill": {
     "duration": 5.950636,
     "end_time": "2023-10-07T10:02:27.021900",
     "exception": false,
     "start_time": "2023-10-07T10:02:21.071264",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import torch \n",
    "from torch import nn\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from torch.utils.data import Dataset\n",
    "from spellchecker import SpellChecker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1875bbf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-07T10:02:27.041212Z",
     "iopub.status.busy": "2023-10-07T10:02:27.040462Z",
     "iopub.status.idle": "2023-10-07T10:02:27.155736Z",
     "shell.execute_reply": "2023-10-07T10:02:27.154813Z"
    },
    "papermill": {
     "duration": 0.125936,
     "end_time": "2023-10-07T10:02:27.157544",
     "exception": false,
     "start_time": "2023-10-07T10:02:27.031608",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7165, 5), (4, 4))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summaries = pd.read_csv('/kaggle/input/commonlit-evaluate-student-summaries/summaries_train.csv')\n",
    "prompts = pd.read_csv('/kaggle/input/commonlit-evaluate-student-summaries/prompts_train.csv')\n",
    "\n",
    "summaries.shape, prompts.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d500423f",
   "metadata": {
    "papermill": {
     "duration": 0.007911,
     "end_time": "2023-10-07T10:02:27.173552",
     "exception": false,
     "start_time": "2023-10-07T10:02:27.165641",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d074724",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-07T10:02:27.191626Z",
     "iopub.status.busy": "2023-10-07T10:02:27.190734Z",
     "iopub.status.idle": "2023-10-07T10:02:27.261735Z",
     "shell.execute_reply": "2023-10-07T10:02:27.260702Z"
    },
    "papermill": {
     "duration": 0.082154,
     "end_time": "2023-10-07T10:02:27.263970",
     "exception": false,
     "start_time": "2023-10-07T10:02:27.181816",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# parameters for training\n",
    "\n",
    "EPOCHS = 5\n",
    "model_name = '/kaggle/input/bert-base-uncased'\n",
    "num_labels = 2\n",
    "learning_rate = 0.001\n",
    "BATCH_SIZE = 20\n",
    "MAX_LENGTH = 256\n",
    "NUM_FOLDS = 5\n",
    "\n",
    "# If there are GPUs available, use the first one \n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0494e578",
   "metadata": {
    "papermill": {
     "duration": 0.008042,
     "end_time": "2023-10-07T10:02:27.280915",
     "exception": false,
     "start_time": "2023-10-07T10:02:27.272873",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf7fbaec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-07T10:02:27.298790Z",
     "iopub.status.busy": "2023-10-07T10:02:27.298482Z",
     "iopub.status.idle": "2023-10-07T10:02:27.368177Z",
     "shell.execute_reply": "2023-10-07T10:02:27.367104Z"
    },
    "papermill": {
     "duration": 0.080942,
     "end_time": "2023-10-07T10:02:27.370312",
     "exception": false,
     "start_time": "2023-10-07T10:02:27.289370",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "STOP_WORDS = set(stopwords.words('english'))\n",
    "\n",
    "spellchecker = SpellChecker()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "885e10ab",
   "metadata": {
    "papermill": {
     "duration": 0.007942,
     "end_time": "2023-10-07T10:02:27.386635",
     "exception": false,
     "start_time": "2023-10-07T10:02:27.378693",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "daf9b4b3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-07T10:02:27.404049Z",
     "iopub.status.busy": "2023-10-07T10:02:27.403728Z",
     "iopub.status.idle": "2023-10-07T10:02:27.409112Z",
     "shell.execute_reply": "2023-10-07T10:02:27.408175Z"
    },
    "papermill": {
     "duration": 0.01599,
     "end_time": "2023-10-07T10:02:27.410826",
     "exception": false,
     "start_time": "2023-10-07T10:02:27.394836",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"[^a-zA-Z0-9]\", \" \", text)\n",
    "    \n",
    "    return text\n",
    "\n",
    "def is_valid_float(x):\n",
    "    return isinstance(x, float) and x == x  # This checks that x is not NaN since NaN != NaN in Python.\n",
    "\n",
    "\n",
    "def get_misspelled_count(text):\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    misspelled = [token for token in spellchecker.unknown(tokens) if token.isalpha()]\n",
    "    \n",
    "    return len(misspelled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cddc810b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-07T10:02:27.428249Z",
     "iopub.status.busy": "2023-10-07T10:02:27.427518Z",
     "iopub.status.idle": "2023-10-07T10:02:27.433369Z",
     "shell.execute_reply": "2023-10-07T10:02:27.432470Z"
    },
    "papermill": {
     "duration": 0.016436,
     "end_time": "2023-10-07T10:02:27.435101",
     "exception": false,
     "start_time": "2023-10-07T10:02:27.418665",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "\n",
    "def ngrams(token, n):\n",
    "    ngrams = zip(*[token[i:] for i in range(n)])\n",
    "    return [\" \".join(ngram) for ngram in ngrams]\n",
    "\n",
    "def ngrams_co_occurence(row, n):\n",
    "    original_tokens = row['prompt_tokens']\n",
    "    summary_tokens = row['summary_tokens']\n",
    "    \n",
    "    original_ngrams = set(ngrams(original_tokens, n))\n",
    "    summary_ngrams = set(ngrams(summary_tokens, n))\n",
    "    \n",
    "    common_ngrams = original_ngrams.intersection(summary_ngrams)\n",
    "    return len(common_ngrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6312fda3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-07T10:02:27.501122Z",
     "iopub.status.busy": "2023-10-07T10:02:27.500481Z",
     "iopub.status.idle": "2023-10-07T10:02:27.505210Z",
     "shell.execute_reply": "2023-10-07T10:02:27.503983Z"
    },
    "papermill": {
     "duration": 0.064238,
     "end_time": "2023-10-07T10:02:27.507207",
     "exception": false,
     "start_time": "2023-10-07T10:02:27.442969",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def check_is_stop_word(word):\n",
    "    return word in STOP_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c68f85c7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-07T10:02:27.525594Z",
     "iopub.status.busy": "2023-10-07T10:02:27.524694Z",
     "iopub.status.idle": "2023-10-07T10:02:27.530750Z",
     "shell.execute_reply": "2023-10-07T10:02:27.529794Z"
    },
    "papermill": {
     "duration": 0.016943,
     "end_time": "2023-10-07T10:02:27.532636",
     "exception": false,
     "start_time": "2023-10-07T10:02:27.515693",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def word_overlap_count(row):\n",
    "    \"\"\" intersection(prompt_text, text) \"\"\"    \n",
    "    prompt_words = row['prompt_tokens']\n",
    "    summary_words = row['summary_tokens']\n",
    "    if STOP_WORDS:\n",
    "        prompt_words = list(filter(check_is_stop_word, prompt_words))\n",
    "        summary_words = list(filter(check_is_stop_word, summary_words))\n",
    "    return len(set(prompt_words).intersection(set(summary_words)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38d8e9a",
   "metadata": {
    "papermill": {
     "duration": 0.008162,
     "end_time": "2023-10-07T10:02:27.550139",
     "exception": false,
     "start_time": "2023-10-07T10:02:27.541977",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### For the train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c4f6ce41",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-07T10:02:27.571054Z",
     "iopub.status.busy": "2023-10-07T10:02:27.570723Z",
     "iopub.status.idle": "2023-10-07T10:02:27.873909Z",
     "shell.execute_reply": "2023-10-07T10:02:27.872862Z"
    },
    "papermill": {
     "duration": 0.315394,
     "end_time": "2023-10-07T10:02:27.876239",
     "exception": false,
     "start_time": "2023-10-07T10:02:27.560845",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = summaries.merge(prompts, on = 'prompt_id', how = 'inner')\n",
    "train.drop(['student_id', 'prompt_id'], axis = 1, inplace = True)\n",
    "\n",
    "train['text_len'] = train['text'].apply(lambda x: len(x.split()))\n",
    "train['prompt_len'] = train['prompt_text'].apply(lambda x: len(x.split()))\n",
    "train['length_ratio'] = train['text_len'] / train['prompt_len']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8773a7c6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-07T10:02:27.894782Z",
     "iopub.status.busy": "2023-10-07T10:02:27.894514Z",
     "iopub.status.idle": "2023-10-07T10:02:32.811256Z",
     "shell.execute_reply": "2023-10-07T10:02:32.810356Z"
    },
    "papermill": {
     "duration": 4.927981,
     "end_time": "2023-10-07T10:02:32.813332",
     "exception": false,
     "start_time": "2023-10-07T10:02:27.885351",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train['text'] = train['text'].apply(lambda x: preprocess_text(x))\n",
    "train['prompt_question'] = train['prompt_question'].apply(lambda x: preprocess_text(x))\n",
    "train['prompt_text'] = train['prompt_text'].apply(lambda x: preprocess_text(x))\n",
    "train['prompt_title'] = train['prompt_title'].apply(lambda x: preprocess_text(x))\n",
    "\n",
    "train['misspelled'] = train['text'].apply(lambda x: get_misspelled_count(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b1f72ae1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-07T10:02:32.833152Z",
     "iopub.status.busy": "2023-10-07T10:02:32.832796Z",
     "iopub.status.idle": "2023-10-07T10:02:55.070608Z",
     "shell.execute_reply": "2023-10-07T10:02:55.069614Z"
    },
    "papermill": {
     "duration": 22.250102,
     "end_time": "2023-10-07T10:02:55.073101",
     "exception": false,
     "start_time": "2023-10-07T10:02:32.822999",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train['prompt_tokens'] = train['prompt_text'].apply(lambda x: word_tokenize(x))\n",
    "train['summary_tokens'] = train['text'].apply(lambda x: word_tokenize(x))\n",
    "\n",
    "train['word_overlap_count'] = train.apply(word_overlap_count, axis = 1)\n",
    "train['bigram_overlap_count'] = train.apply(ngrams_co_occurence, args=(2,), axis = 1)\n",
    "train['trigram_overlap_count'] = train.apply(ngrams_co_occurence, args=(3,), axis = 1)\n",
    "\n",
    "train['bigram_overlap_ratio'] = train['bigram_overlap_count'] / (train['text_len'] - 1)\n",
    "train['trigram_overlap_ratio'] = train['trigram_overlap_count'] / (train['text_len'] - 2)\n",
    "\n",
    "train.drop(['prompt_tokens', 'summary_tokens'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "228dd56b",
   "metadata": {
    "papermill": {
     "duration": 0.007822,
     "end_time": "2023-10-07T10:02:55.089492",
     "exception": false,
     "start_time": "2023-10-07T10:02:55.081670",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### For the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "242b56d4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-07T10:02:55.106872Z",
     "iopub.status.busy": "2023-10-07T10:02:55.106601Z",
     "iopub.status.idle": "2023-10-07T10:02:55.123580Z",
     "shell.execute_reply": "2023-10-07T10:02:55.122726Z"
    },
    "papermill": {
     "duration": 0.027794,
     "end_time": "2023-10-07T10:02:55.125266",
     "exception": false,
     "start_time": "2023-10-07T10:02:55.097472",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_summaries = pd.read_csv('/kaggle/input/commonlit-evaluate-student-summaries/summaries_test.csv')\n",
    "test_prompt = pd.read_csv('/kaggle/input/commonlit-evaluate-student-summaries/prompts_test.csv')\n",
    "\n",
    "student_ids = test_summaries['student_id'].values.tolist()\n",
    "\n",
    "test = test_summaries.merge(test_prompt, on = 'prompt_id', how = 'inner')\n",
    "test.drop(['student_id', 'prompt_id'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0329ce47",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-07T10:02:55.142431Z",
     "iopub.status.busy": "2023-10-07T10:02:55.141647Z",
     "iopub.status.idle": "2023-10-07T10:02:55.153905Z",
     "shell.execute_reply": "2023-10-07T10:02:55.153152Z"
    },
    "papermill": {
     "duration": 0.022587,
     "end_time": "2023-10-07T10:02:55.155693",
     "exception": false,
     "start_time": "2023-10-07T10:02:55.133106",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test['text_len'] = test['text'].apply(lambda x: len(x.split()))\n",
    "test['prompt_len'] = test['prompt_text'].apply(lambda x: len(x.split()))\n",
    "test['length_ratio'] = test['text_len'] / train['prompt_len']\n",
    "\n",
    "test['text'] = test['text'].apply(lambda x: preprocess_text(x))\n",
    "test['prompt_question'] = test['prompt_question'].apply(lambda x: preprocess_text(x))\n",
    "test['prompt_text'] = test['prompt_text'].apply(lambda x: preprocess_text(x))\n",
    "test['prompt_title'] = test['prompt_title'].apply(lambda x: preprocess_text(x))\n",
    "\n",
    "test['misspelled'] = test['text'].apply(lambda x: get_misspelled_count(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f7da407e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-07T10:02:55.172721Z",
     "iopub.status.busy": "2023-10-07T10:02:55.172354Z",
     "iopub.status.idle": "2023-10-07T10:02:55.184930Z",
     "shell.execute_reply": "2023-10-07T10:02:55.183988Z"
    },
    "papermill": {
     "duration": 0.022821,
     "end_time": "2023-10-07T10:02:55.186675",
     "exception": false,
     "start_time": "2023-10-07T10:02:55.163854",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test['prompt_tokens'] = test['prompt_text'].apply(lambda x: word_tokenize(x))\n",
    "test['summary_tokens'] = test['text'].apply(lambda x: word_tokenize(x))\n",
    "\n",
    "test['word_overlap_count'] = test.apply(word_overlap_count, axis = 1)\n",
    "test['bigram_overlap_count'] = test.apply(ngrams_co_occurence, args=(2,), axis = 1)\n",
    "test['trigram_overlap_count'] = test.apply(ngrams_co_occurence, args=(3,), axis = 1)\n",
    "\n",
    "test['bigram_overlap_ratio'] = test['bigram_overlap_count'] / (test['text_len'] - 1)\n",
    "test['trigram_overlap_ratio'] = test['trigram_overlap_count'] / (test['text_len'] - 2)\n",
    "\n",
    "test.drop(['prompt_tokens', 'summary_tokens'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a4a2ce",
   "metadata": {
    "papermill": {
     "duration": 0.00786,
     "end_time": "2023-10-07T10:02:55.202789",
     "exception": false,
     "start_time": "2023-10-07T10:02:55.194929",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "88e4ae6a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-07T10:02:55.220160Z",
     "iopub.status.busy": "2023-10-07T10:02:55.219900Z",
     "iopub.status.idle": "2023-10-07T10:02:56.893193Z",
     "shell.execute_reply": "2023-10-07T10:02:56.892286Z"
    },
    "papermill": {
     "duration": 1.684498,
     "end_time": "2023-10-07T10:02:56.895309",
     "exception": false,
     "start_time": "2023-10-07T10:02:55.210811",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e4a84b65",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-07T10:02:56.913007Z",
     "iopub.status.busy": "2023-10-07T10:02:56.912620Z",
     "iopub.status.idle": "2023-10-07T10:02:56.921830Z",
     "shell.execute_reply": "2023-10-07T10:02:56.920889Z"
    },
    "papermill": {
     "duration": 0.019668,
     "end_time": "2023-10-07T10:02:56.923499",
     "exception": false,
     "start_time": "2023-10-07T10:02:56.903831",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sep = tokenizer.sep_token\n",
    "\n",
    "train['inputs'] = train['prompt_question'] + sep + train['text']\n",
    "test['inputs'] = test['prompt_question'] + sep + test['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a76a20e8",
   "metadata": {
    "papermill": {
     "duration": 0.007766,
     "end_time": "2023-10-07T10:02:56.938960",
     "exception": false,
     "start_time": "2023-10-07T10:02:56.931194",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1f2c5cd9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-07T10:02:56.956214Z",
     "iopub.status.busy": "2023-10-07T10:02:56.955766Z",
     "iopub.status.idle": "2023-10-07T10:02:56.962841Z",
     "shell.execute_reply": "2023-10-07T10:02:56.961871Z"
    },
    "papermill": {
     "duration": 0.017362,
     "end_time": "2023-10-07T10:02:56.964501",
     "exception": false,
     "start_time": "2023-10-07T10:02:56.947139",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TextDataset(Dataset):\n",
    "    def __init__(self, texts, feature_cols, tokenizer, max_length, targets = None, is_train = False):\n",
    "        self.texts = texts\n",
    "        self.feature_cols = feature_cols\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.is_train = is_train\n",
    "        \n",
    "        if self.is_train:\n",
    "            self.targets = targets\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        \n",
    "        encoding = self.tokenizer.encode_plus(text,\n",
    "                                             add_special_tokens = True,\n",
    "                                             max_length = self.max_length,\n",
    "                                             return_token_type_ids = False,\n",
    "                                             padding = 'max_length',\n",
    "                                             truncation = True,\n",
    "                                             return_attention_mask = True,\n",
    "                                             return_tensors = 'pt')\n",
    "        if self.is_train:\n",
    "            item = {'input_ids': encoding['input_ids'].flatten(),\n",
    "                    'attention_mask': encoding['attention_mask'].flatten(),\n",
    "                   'feature_cols': torch.tensor(self.feature_cols[idx], dtype=torch.float), \n",
    "                   'target': torch.tensor(self.targets[idx], dtype=torch.float)}\n",
    "        else:\n",
    "            item = {'input_ids': encoding['input_ids'].flatten(),\n",
    "                   'attention_mask': encoding['attention_mask'].flatten(),\n",
    "                   'feature_cols': torch.tensor(self.feature_cols[idx], dtype=torch.float)}\n",
    "        \n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e03b1ab6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-07T10:02:56.981999Z",
     "iopub.status.busy": "2023-10-07T10:02:56.981248Z",
     "iopub.status.idle": "2023-10-07T10:02:56.985813Z",
     "shell.execute_reply": "2023-10-07T10:02:56.985063Z"
    },
    "papermill": {
     "duration": 0.015395,
     "end_time": "2023-10-07T10:02:56.987552",
     "exception": false,
     "start_time": "2023-10-07T10:02:56.972157",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "feature_cols = ['text_len', 'prompt_len', 'length_ratio', 'misspelled',\n",
    "                'word_overlap_count', 'bigram_overlap_count', 'trigram_overlap_count',\n",
    "               'bigram_overlap_ratio', 'trigram_overlap_ratio']\n",
    "\n",
    "targets = ['content', 'wording']\n",
    "feature_col_size = len(feature_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "51c5cb27",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-07T10:02:57.004308Z",
     "iopub.status.busy": "2023-10-07T10:02:57.003659Z",
     "iopub.status.idle": "2023-10-07T10:02:57.011694Z",
     "shell.execute_reply": "2023-10-07T10:02:57.010915Z"
    },
    "papermill": {
     "duration": 0.018158,
     "end_time": "2023-10-07T10:02:57.013344",
     "exception": false,
     "start_time": "2023-10-07T10:02:56.995186",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset = TextDataset(texts = train['inputs'], \n",
    "                            feature_cols = train[feature_cols].values, \n",
    "                            tokenizer = tokenizer, \n",
    "                            max_length = MAX_LENGTH,\n",
    "                            targets = train[targets].values,\n",
    "                           is_train = True)\n",
    "\n",
    "test_dataset = TextDataset(texts = test['inputs'],\n",
    "                          feature_cols = test[feature_cols].values,\n",
    "                          tokenizer = tokenizer,\n",
    "                          max_length = MAX_LENGTH,\n",
    "                          is_train = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bc86608b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-07T10:02:57.030513Z",
     "iopub.status.busy": "2023-10-07T10:02:57.030267Z",
     "iopub.status.idle": "2023-10-07T10:02:57.034158Z",
     "shell.execute_reply": "2023-10-07T10:02:57.033299Z"
    },
    "papermill": {
     "duration": 0.014204,
     "end_time": "2023-10-07T10:02:57.035800",
     "exception": false,
     "start_time": "2023-10-07T10:02:57.021596",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load the dataset using pytorch's dataloader tool\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "test_loader = DataLoader(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "813d3dc1",
   "metadata": {
    "papermill": {
     "duration": 0.00752,
     "end_time": "2023-10-07T10:02:57.051026",
     "exception": false,
     "start_time": "2023-10-07T10:02:57.043506",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "248df7e3",
   "metadata": {
    "papermill": {
     "duration": 0.007497,
     "end_time": "2023-10-07T10:02:57.066263",
     "exception": false,
     "start_time": "2023-10-07T10:02:57.058766",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### LLM Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4293747",
   "metadata": {
    "papermill": {
     "duration": 0.007566,
     "end_time": "2023-10-07T10:02:57.081525",
     "exception": false,
     "start_time": "2023-10-07T10:02:57.073959",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "I have decided to add cross-validation strategy to the training process of the model from Experiment 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e8829f0c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-07T10:02:57.099021Z",
     "iopub.status.busy": "2023-10-07T10:02:57.098277Z",
     "iopub.status.idle": "2023-10-07T10:02:57.111377Z",
     "shell.execute_reply": "2023-10-07T10:02:57.110621Z"
    },
    "papermill": {
     "duration": 0.023404,
     "end_time": "2023-10-07T10:02:57.113041",
     "exception": false,
     "start_time": "2023-10-07T10:02:57.089637",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1a8d9f35",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-07T10:02:57.129758Z",
     "iopub.status.busy": "2023-10-07T10:02:57.129175Z",
     "iopub.status.idle": "2023-10-07T10:02:57.134631Z",
     "shell.execute_reply": "2023-10-07T10:02:57.133716Z"
    },
    "papermill": {
     "duration": 0.01549,
     "end_time": "2023-10-07T10:02:57.136195",
     "exception": false,
     "start_time": "2023-10-07T10:02:57.120705",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CustomModel(nn.Module):\n",
    "    def __init__(self, model_name, num_labels, feature_col_size):\n",
    "        \"\"\"Instantiate a model that can fit on the dataset\"\"\"\n",
    "        \n",
    "        super().__init__()\n",
    "        self.model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels = num_labels)\n",
    "        self.numerics = nn.Linear(feature_col_size, 16)\n",
    "        self.final_layer = nn.Linear(16 + num_labels, num_labels)\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask, feature_cols):\n",
    "        text_output = self.model(input_ids = input_ids, attention_mask = attention_mask)\n",
    "        numerics = self.numerics(feature_cols)\n",
    "        concat_features = torch.cat([text_output.logits, numerics], dim = 1)\n",
    "        \n",
    "        final_output = self.final_layer(concat_features)\n",
    "        \n",
    "        return final_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3f9dbc87",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-07T10:02:57.152710Z",
     "iopub.status.busy": "2023-10-07T10:02:57.152339Z",
     "iopub.status.idle": "2023-10-07T10:02:57.156289Z",
     "shell.execute_reply": "2023-10-07T10:02:57.155456Z"
    },
    "papermill": {
     "duration": 0.01401,
     "end_time": "2023-10-07T10:02:57.157925",
     "exception": false,
     "start_time": "2023-10-07T10:02:57.143915",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# loss and optimizer\n",
    "\n",
    "from torch.optim import Adam\n",
    "from torch.nn import MSELoss\n",
    "\n",
    "loss_function = MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "152b12c3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-07T10:02:57.175379Z",
     "iopub.status.busy": "2023-10-07T10:02:57.174548Z",
     "iopub.status.idle": "2023-10-07T10:02:57.181184Z",
     "shell.execute_reply": "2023-10-07T10:02:57.180371Z"
    },
    "papermill": {
     "duration": 0.017227,
     "end_time": "2023-10-07T10:02:57.182888",
     "exception": false,
     "start_time": "2023-10-07T10:02:57.165661",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_step(train_loader):\n",
    "    \"\"\"The training loop for the dataset\"\"\"\n",
    "    \n",
    "    for step, batch in enumerate(train_loader):\n",
    "        epochal_loss = 0\n",
    "        steps = 0\n",
    "        \n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        feature_cols = batch['feature_cols'].to(device)\n",
    "        targets = batch['target'].to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(input_ids, attention_mask, feature_cols)\n",
    "        loss = loss_function(outputs, targets)\n",
    "        epochal_loss += loss\n",
    "        steps += 1\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if step % 50 == 0:\n",
    "            print(f\"Epoch {epoch + 1} Step {step} Loss {loss.item()}\")\n",
    "            \n",
    "    print(f\"Epoch {epoch + 1} Train Loss: {epochal_loss/steps}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a2fcd5a3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-07T10:02:57.200938Z",
     "iopub.status.busy": "2023-10-07T10:02:57.200134Z",
     "iopub.status.idle": "2023-10-07T10:02:57.206319Z",
     "shell.execute_reply": "2023-10-07T10:02:57.205578Z"
    },
    "papermill": {
     "duration": 0.016993,
     "end_time": "2023-10-07T10:02:57.207999",
     "exception": false,
     "start_time": "2023-10-07T10:02:57.191006",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def val_step(val_loader):\n",
    "    \"\"\"The validation loop\"\"\"\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for step, batch in enumerate(val_loader):\n",
    "            epochal_loss = 0\n",
    "            steps = 0\n",
    "            \n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            feature_cols = batch['feature_cols'].to(device)\n",
    "            targets = batch['target'].to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(input_ids, attention_mask, feature_cols)\n",
    "            epochal_loss += loss_function(outputs, targets)\n",
    "            steps += 1\n",
    "            \n",
    "        avg_val_loss = epochal_loss/steps\n",
    "        print(f\"Epoch {epoch + 1} Validation Loss: {avg_val_loss}\")\n",
    "        \n",
    "    return avg_val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1994c141",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-07T10:02:57.224794Z",
     "iopub.status.busy": "2023-10-07T10:02:57.224453Z",
     "iopub.status.idle": "2023-10-07T11:05:27.479195Z",
     "shell.execute_reply": "2023-10-07T11:05:27.477865Z"
    },
    "papermill": {
     "duration": 3750.265187,
     "end_time": "2023-10-07T11:05:27.481007",
     "exception": false,
     "start_time": "2023-10-07T10:02:57.215820",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 - Train Indices: [   0    1    2 ... 7161 7163 7164], Val Indices: [   8   14   17 ... 7157 7159 7162]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at /kaggle/input/bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Step 0 Loss 6244.92529296875\n",
      "Epoch 1 Step 50 Loss 37.08399200439453\n",
      "Epoch 1 Step 100 Loss 10.058191299438477\n",
      "Epoch 1 Step 150 Loss 6.962139129638672\n",
      "Epoch 1 Step 200 Loss 7.272191047668457\n",
      "Epoch 1 Step 250 Loss 10.922537803649902\n",
      "Epoch 1 Train Loss: 6.830264568328857\n",
      "Epoch 1 Validation Loss: 2.7088258266448975\n",
      "Total time for training epoch 1: 149.25971484184265s\n",
      "\n",
      "\n",
      "Epoch 2 Step 0 Loss 6.016249179840088\n",
      "Epoch 2 Step 50 Loss 6.373027324676514\n",
      "Epoch 2 Step 100 Loss 4.445347785949707\n",
      "Epoch 2 Step 150 Loss 2.167292356491089\n",
      "Epoch 2 Step 200 Loss 2.2981863021850586\n",
      "Epoch 2 Step 250 Loss 1.6112492084503174\n",
      "Epoch 2 Train Loss: 1.6405367851257324\n",
      "Epoch 2 Validation Loss: 1.0973751544952393\n",
      "Total time for training epoch 2: 147.86746335029602s\n",
      "\n",
      "\n",
      "Epoch 3 Step 0 Loss 2.4855878353118896\n",
      "Epoch 3 Step 50 Loss 1.2881046533584595\n",
      "Epoch 3 Step 100 Loss 0.9404897689819336\n",
      "Epoch 3 Step 150 Loss 1.4881151914596558\n",
      "Epoch 3 Step 200 Loss 1.0762569904327393\n",
      "Epoch 3 Step 250 Loss 1.1293630599975586\n",
      "Epoch 3 Train Loss: 1.048113226890564\n",
      "Epoch 3 Validation Loss: 0.5254553556442261\n",
      "Total time for training epoch 3: 148.5046203136444s\n",
      "\n",
      "\n",
      "Epoch 4 Step 0 Loss 0.8897460103034973\n",
      "Epoch 4 Step 50 Loss 1.2643240690231323\n",
      "Epoch 4 Step 100 Loss 0.8010364770889282\n",
      "Epoch 4 Step 150 Loss 0.7709321975708008\n",
      "Epoch 4 Step 200 Loss 0.7275574207305908\n",
      "Epoch 4 Step 250 Loss 0.8996963500976562\n",
      "Epoch 4 Train Loss: 0.874884307384491\n",
      "Epoch 4 Validation Loss: 0.4597359001636505\n",
      "Total time for training epoch 4: 148.753347158432s\n",
      "\n",
      "\n",
      "Epoch 5 Step 0 Loss 0.8248569369316101\n",
      "Epoch 5 Step 50 Loss 0.734866738319397\n",
      "Epoch 5 Step 100 Loss 0.49559590220451355\n",
      "Epoch 5 Step 150 Loss 0.5591533184051514\n",
      "Epoch 5 Step 200 Loss 1.3227157592773438\n",
      "Epoch 5 Step 250 Loss 1.5492805242538452\n",
      "Epoch 5 Train Loss: 0.500971257686615\n",
      "Epoch 5 Validation Loss: 0.49386245012283325\n",
      "Total time for training epoch 5: 148.80259537696838s\n",
      "\n",
      "\n",
      "Fold 2 - Train Indices: [   0    1    2 ... 7162 7163 7164], Val Indices: [  12   15   26 ... 7152 7160 7161]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at /kaggle/input/bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Step 0 Loss 11569.0869140625\n",
      "Epoch 1 Step 50 Loss 239.02114868164062\n",
      "Epoch 1 Step 100 Loss 55.7779655456543\n",
      "Epoch 1 Step 150 Loss 21.54164695739746\n",
      "Epoch 1 Step 200 Loss 23.619998931884766\n",
      "Epoch 1 Step 250 Loss 9.282065391540527\n",
      "Epoch 1 Train Loss: 9.125484466552734\n",
      "Epoch 1 Validation Loss: 1.0876491069793701\n",
      "Total time for training epoch 1: 148.93122625350952s\n",
      "\n",
      "\n",
      "Epoch 2 Step 0 Loss 13.822662353515625\n",
      "Epoch 2 Step 50 Loss 7.173825263977051\n",
      "Epoch 2 Step 100 Loss 7.3341240882873535\n",
      "Epoch 2 Step 150 Loss 4.512558937072754\n",
      "Epoch 2 Step 200 Loss 3.654104232788086\n",
      "Epoch 2 Step 250 Loss 2.5600335597991943\n",
      "Epoch 2 Train Loss: 2.165461540222168\n",
      "Epoch 2 Validation Loss: 0.6472029089927673\n",
      "Total time for training epoch 2: 148.9727008342743s\n",
      "\n",
      "\n",
      "Epoch 3 Step 0 Loss 2.2703800201416016\n",
      "Epoch 3 Step 50 Loss 1.7765941619873047\n",
      "Epoch 3 Step 100 Loss 1.259765386581421\n",
      "Epoch 3 Step 150 Loss 1.2509292364120483\n",
      "Epoch 3 Step 200 Loss 1.6565626859664917\n",
      "Epoch 3 Step 250 Loss 4.878007411956787\n",
      "Epoch 3 Train Loss: 1.0848017930984497\n",
      "Epoch 3 Validation Loss: 0.6053933501243591\n",
      "Total time for training epoch 3: 149.18023252487183s\n",
      "\n",
      "\n",
      "Epoch 4 Step 0 Loss 1.8391987085342407\n",
      "Epoch 4 Step 50 Loss 1.2685678005218506\n",
      "Epoch 4 Step 100 Loss 1.7137151956558228\n",
      "Epoch 4 Step 150 Loss 1.1347359418869019\n",
      "Epoch 4 Step 200 Loss 1.3092600107192993\n",
      "Epoch 4 Step 250 Loss 1.0991863012313843\n",
      "Epoch 4 Train Loss: 0.9793577194213867\n",
      "Epoch 4 Validation Loss: 0.41137996315956116\n",
      "Total time for training epoch 4: 149.15692806243896s\n",
      "\n",
      "\n",
      "Epoch 5 Step 0 Loss 0.8120537996292114\n",
      "Epoch 5 Step 50 Loss 1.2782350778579712\n",
      "Epoch 5 Step 100 Loss 1.0423580408096313\n",
      "Epoch 5 Step 150 Loss 1.1103612184524536\n",
      "Epoch 5 Step 200 Loss 0.9148629307746887\n",
      "Epoch 5 Step 250 Loss 0.5636717677116394\n",
      "Epoch 5 Train Loss: 1.0373506546020508\n",
      "Epoch 5 Validation Loss: 0.3681328594684601\n",
      "Total time for training epoch 5: 149.0511224269867s\n",
      "\n",
      "\n",
      "Fold 3 - Train Indices: [   1    2    3 ... 7160 7161 7162], Val Indices: [   0    6    7 ... 7150 7163 7164]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at /kaggle/input/bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Step 0 Loss 705.8566284179688\n",
      "Epoch 1 Step 50 Loss 4.936731338500977\n",
      "Epoch 1 Step 100 Loss 1.4909604787826538\n",
      "Epoch 1 Step 150 Loss 0.4773823320865631\n",
      "Epoch 1 Step 200 Loss 0.7201003432273865\n",
      "Epoch 1 Step 250 Loss 0.614048182964325\n",
      "Epoch 1 Train Loss: 0.7321339845657349\n",
      "Epoch 1 Validation Loss: 0.711833119392395\n",
      "Total time for training epoch 1: 149.4302523136139s\n",
      "\n",
      "\n",
      "Epoch 2 Step 0 Loss 0.5137926936149597\n",
      "Epoch 2 Step 50 Loss 0.4345259368419647\n",
      "Epoch 2 Step 100 Loss 0.3886605203151703\n",
      "Epoch 2 Step 150 Loss 0.36364051699638367\n",
      "Epoch 2 Step 200 Loss 0.5983284115791321\n",
      "Epoch 2 Step 250 Loss 0.3910214602947235\n",
      "Epoch 2 Train Loss: 0.38537728786468506\n",
      "Epoch 2 Validation Loss: 0.6030328869819641\n",
      "Total time for training epoch 2: 149.42120361328125s\n",
      "\n",
      "\n",
      "Epoch 3 Step 0 Loss 0.4606975018978119\n",
      "Epoch 3 Step 50 Loss 0.372419536113739\n",
      "Epoch 3 Step 100 Loss 0.45793938636779785\n",
      "Epoch 3 Step 150 Loss 0.48611971735954285\n",
      "Epoch 3 Step 200 Loss 0.40141841769218445\n",
      "Epoch 3 Step 250 Loss 0.329709529876709\n",
      "Epoch 3 Train Loss: 0.3589763045310974\n",
      "Epoch 3 Validation Loss: 0.47082096338272095\n",
      "Total time for training epoch 3: 149.45279383659363s\n",
      "\n",
      "\n",
      "Epoch 4 Step 0 Loss 0.47480079531669617\n",
      "Epoch 4 Step 50 Loss 0.563651978969574\n",
      "Epoch 4 Step 100 Loss 1.3830788135528564\n",
      "Epoch 4 Step 150 Loss 0.27620169520378113\n",
      "Epoch 4 Step 200 Loss 0.38088247179985046\n",
      "Epoch 4 Step 250 Loss 0.44359514117240906\n",
      "Epoch 4 Train Loss: 0.2782108783721924\n",
      "Epoch 4 Validation Loss: 0.6011123061180115\n",
      "Total time for training epoch 4: 149.4329936504364s\n",
      "\n",
      "\n",
      "Epoch 5 Step 0 Loss 0.4114542603492737\n",
      "Epoch 5 Step 50 Loss 0.44387108087539673\n",
      "Epoch 5 Step 100 Loss 0.34608158469200134\n",
      "Epoch 5 Step 150 Loss 0.4126347005367279\n",
      "Epoch 5 Step 200 Loss 0.5210102200508118\n",
      "Epoch 5 Step 250 Loss 0.6150850653648376\n",
      "Epoch 5 Train Loss: 0.882060706615448\n",
      "Epoch 5 Validation Loss: 0.4530101716518402\n",
      "Total time for training epoch 5: 149.34765672683716s\n",
      "\n",
      "\n",
      "Fold 4 - Train Indices: [   0    3    4 ... 7162 7163 7164], Val Indices: [   1    2   10 ... 7148 7154 7158]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at /kaggle/input/bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Step 0 Loss 18067.51953125\n",
      "Epoch 1 Step 50 Loss 358.7878112792969\n",
      "Epoch 1 Step 100 Loss 94.67247772216797\n",
      "Epoch 1 Step 150 Loss 69.97544860839844\n",
      "Epoch 1 Step 200 Loss 15.170097351074219\n",
      "Epoch 1 Step 250 Loss 22.52130126953125\n",
      "Epoch 1 Train Loss: 22.859966278076172\n",
      "Epoch 1 Validation Loss: 6.443268299102783\n",
      "Total time for training epoch 1: 149.32205367088318s\n",
      "\n",
      "\n",
      "Epoch 2 Step 0 Loss 18.337970733642578\n",
      "Epoch 2 Step 50 Loss 12.207226753234863\n",
      "Epoch 2 Step 100 Loss 12.697649002075195\n",
      "Epoch 2 Step 150 Loss 10.027022361755371\n",
      "Epoch 2 Step 200 Loss 10.943381309509277\n",
      "Epoch 2 Step 250 Loss 7.662580966949463\n",
      "Epoch 2 Train Loss: 4.088892936706543\n",
      "Epoch 2 Validation Loss: 2.4055023193359375\n",
      "Total time for training epoch 2: 149.23307490348816s\n",
      "\n",
      "\n",
      "Epoch 3 Step 0 Loss 3.822578191757202\n",
      "Epoch 3 Step 50 Loss 4.33130407333374\n",
      "Epoch 3 Step 100 Loss 2.7564494609832764\n",
      "Epoch 3 Step 150 Loss 2.3577280044555664\n",
      "Epoch 3 Step 200 Loss 1.269821047782898\n",
      "Epoch 3 Step 250 Loss 1.292689323425293\n",
      "Epoch 3 Train Loss: 1.5970176458358765\n",
      "Epoch 3 Validation Loss: 1.1715877056121826\n",
      "Total time for training epoch 3: 149.15368008613586s\n",
      "\n",
      "\n",
      "Epoch 4 Step 0 Loss 4.220429420471191\n",
      "Epoch 4 Step 50 Loss 1.0224523544311523\n",
      "Epoch 4 Step 100 Loss 1.3236392736434937\n",
      "Epoch 4 Step 150 Loss 1.2227015495300293\n",
      "Epoch 4 Step 200 Loss 1.1621681451797485\n",
      "Epoch 4 Step 250 Loss 0.8441230654716492\n",
      "Epoch 4 Train Loss: 0.6793514490127563\n",
      "Epoch 4 Validation Loss: 0.7926967740058899\n",
      "Total time for training epoch 4: 149.16160917282104s\n",
      "\n",
      "\n",
      "Epoch 5 Step 0 Loss 0.9371415972709656\n",
      "Epoch 5 Step 50 Loss 1.1058015823364258\n",
      "Epoch 5 Step 100 Loss 0.568428099155426\n",
      "Epoch 5 Step 150 Loss 0.6506977081298828\n",
      "Epoch 5 Step 200 Loss 1.1282868385314941\n",
      "Epoch 5 Step 250 Loss 3.9072539806365967\n",
      "Epoch 5 Train Loss: 2.2813539505004883\n",
      "Epoch 5 Validation Loss: 0.6640745401382446\n",
      "Total time for training epoch 5: 149.18622660636902s\n",
      "\n",
      "\n",
      "Fold 5 - Train Indices: [   0    1    2 ... 7162 7163 7164], Val Indices: [   3    4    5 ... 7149 7151 7155]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at /kaggle/input/bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Step 0 Loss 1881.94921875\n",
      "Epoch 1 Step 50 Loss 66.45091247558594\n",
      "Epoch 1 Step 100 Loss 12.326605796813965\n",
      "Epoch 1 Step 150 Loss 4.466763973236084\n",
      "Epoch 1 Step 200 Loss 3.495629072189331\n",
      "Epoch 1 Step 250 Loss 2.1115715503692627\n",
      "Epoch 1 Train Loss: 1.2123820781707764\n",
      "Epoch 1 Validation Loss: 1.5921350717544556\n",
      "Total time for training epoch 1: 148.8720920085907s\n",
      "\n",
      "\n",
      "Epoch 2 Step 0 Loss 1.7758249044418335\n",
      "Epoch 2 Step 50 Loss 1.6658114194869995\n",
      "Epoch 2 Step 100 Loss 1.7134370803833008\n",
      "Epoch 2 Step 150 Loss 0.839093804359436\n",
      "Epoch 2 Step 200 Loss 0.7574621438980103\n",
      "Epoch 2 Step 250 Loss 0.6621996164321899\n",
      "Epoch 2 Train Loss: 0.6009676456451416\n",
      "Epoch 2 Validation Loss: 0.5863232612609863\n",
      "Total time for training epoch 2: 149.14570236206055s\n",
      "\n",
      "\n",
      "Epoch 3 Step 0 Loss 0.7721171379089355\n",
      "Epoch 3 Step 50 Loss 0.9878345727920532\n",
      "Epoch 3 Step 100 Loss 0.4535995423793793\n",
      "Epoch 3 Step 150 Loss 0.43723687529563904\n",
      "Epoch 3 Step 200 Loss 0.48605093359947205\n",
      "Epoch 3 Step 250 Loss 0.5418254137039185\n",
      "Epoch 3 Train Loss: 0.6613508462905884\n",
      "Epoch 3 Validation Loss: 0.5609384775161743\n",
      "Total time for training epoch 3: 149.23502588272095s\n",
      "\n",
      "\n",
      "Epoch 4 Step 0 Loss 0.6017581224441528\n",
      "Epoch 4 Step 50 Loss 0.5591952204704285\n",
      "Epoch 4 Step 100 Loss 0.5303670763969421\n",
      "Epoch 4 Step 150 Loss 0.30607402324676514\n",
      "Epoch 4 Step 200 Loss 0.5673856139183044\n",
      "Epoch 4 Step 250 Loss 0.29255157709121704\n",
      "Epoch 4 Train Loss: 0.4303051829338074\n",
      "Epoch 4 Validation Loss: 0.3992096185684204\n",
      "Total time for training epoch 4: 149.0999140739441s\n",
      "\n",
      "\n",
      "Epoch 5 Step 0 Loss 0.3418806493282318\n",
      "Epoch 5 Step 50 Loss 0.40196332335472107\n",
      "Epoch 5 Step 100 Loss 0.5454059839248657\n",
      "Epoch 5 Step 150 Loss 0.2509799599647522\n",
      "Epoch 5 Step 200 Loss 0.36146649718284607\n",
      "Epoch 5 Step 250 Loss 0.49346455931663513\n",
      "Epoch 5 Train Loss: 0.47063231468200684\n",
      "Epoch 5 Validation Loss: 0.3772795498371124\n",
      "Total time for training epoch 5: 149.17793464660645s\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "best_model = None\n",
    "best_val_loss = float('inf')\n",
    "kf = KFold(n_splits = 5, shuffle = True, random_state = 42)\n",
    "\n",
    "for fold, (train_index, val_index) in enumerate(kf.split(train_dataset)):\n",
    "    print(f\"Fold {fold + 1} - Train Indices: {train_index}, Val Indices: {val_index}\")\n",
    "    train_subset = torch.utils.data.Subset(train_dataset, train_index)\n",
    "    val_subset = torch.utils.data.Subset(train_dataset, val_index)\n",
    "    \n",
    "    train_loader = DataLoader(train_subset, batch_size = BATCH_SIZE, shuffle = True)\n",
    "    val_loader = DataLoader(val_subset, batch_size = BATCH_SIZE)\n",
    "    \n",
    "    model = CustomModel(model_name, num_labels, feature_col_size)\n",
    "    model.to(device)\n",
    "    \n",
    "    optimizer = Adam(model.parameters(), lr = learning_rate)\n",
    "    \n",
    "    for epoch in range(EPOCHS):\n",
    "        start = time.time()\n",
    "        \n",
    "        train_step(train_loader = train_loader)\n",
    "        avg_val_loss = val_step(val_loader = val_loader)\n",
    "        \n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            best_model = model.state_dict()\n",
    "        \n",
    "        print(f\"Total time for training epoch {epoch + 1}: {time.time() - start}s\")\n",
    "        print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "766fac1f",
   "metadata": {
    "papermill": {
     "duration": 0.016093,
     "end_time": "2023-10-07T11:05:27.514763",
     "exception": false,
     "start_time": "2023-10-07T11:05:27.498670",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "919361d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-07T11:05:27.548757Z",
     "iopub.status.busy": "2023-10-07T11:05:27.548061Z",
     "iopub.status.idle": "2023-10-07T11:05:28.817324Z",
     "shell.execute_reply": "2023-10-07T11:05:28.816475Z"
    },
    "papermill": {
     "duration": 1.288539,
     "end_time": "2023-10-07T11:05:28.819493",
     "exception": false,
     "start_time": "2023-10-07T11:05:27.530954",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at /kaggle/input/bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an instance of your CustomModel\n",
    "model = CustomModel(model_name, num_labels, feature_col_size)\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "model.load_state_dict(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d848fbb9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-07T11:05:28.853547Z",
     "iopub.status.busy": "2023-10-07T11:05:28.853254Z",
     "iopub.status.idle": "2023-10-07T11:05:28.914137Z",
     "shell.execute_reply": "2023-10-07T11:05:28.913213Z"
    },
    "papermill": {
     "duration": 0.079941,
     "end_time": "2023-10-07T11:05:28.916234",
     "exception": false,
     "start_time": "2023-10-07T11:05:28.836293",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "preds = []\n",
    "\n",
    "for batch in test_loader:\n",
    "    with torch.no_grad():\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        feature_cols = batch['feature_cols'].to(device)\n",
    "        \n",
    "        outputs = model(input_ids, attention_mask, feature_cols)\n",
    "        preds.extend(outputs.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b4231664",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-07T11:05:28.955743Z",
     "iopub.status.busy": "2023-10-07T11:05:28.954606Z",
     "iopub.status.idle": "2023-10-07T11:05:28.964697Z",
     "shell.execute_reply": "2023-10-07T11:05:28.963459Z"
    },
    "papermill": {
     "duration": 0.032982,
     "end_time": "2023-10-07T11:05:28.966932",
     "exception": false,
     "start_time": "2023-10-07T11:05:28.933950",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "submission_llm = pd.DataFrame({\n",
    "    'student_id': student_ids,\n",
    "    'content_5': [pred[0] for pred in preds],\n",
    "    'wording_5': [pred[1] for pred in preds]\n",
    "})\n",
    "\n",
    "cols_to_check = ['wording_5', 'content_5']\n",
    "submission_llm[cols_to_check] = submission_llm[cols_to_check].applymap(lambda x: x if is_valid_float(x) else 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6f94a226",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-07T11:05:29.007481Z",
     "iopub.status.busy": "2023-10-07T11:05:29.007090Z",
     "iopub.status.idle": "2023-10-07T11:05:29.021582Z",
     "shell.execute_reply": "2023-10-07T11:05:29.020327Z"
    },
    "papermill": {
     "duration": 0.037327,
     "end_time": "2023-10-07T11:05:29.023785",
     "exception": false,
     "start_time": "2023-10-07T11:05:28.986458",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>student_id</th>\n",
       "      <th>content_5</th>\n",
       "      <th>wording_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000000ffffff</td>\n",
       "      <td>0.139513</td>\n",
       "      <td>-1.091022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>111111eeeeee</td>\n",
       "      <td>0.139513</td>\n",
       "      <td>-1.091022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>222222cccccc</td>\n",
       "      <td>0.139513</td>\n",
       "      <td>-1.091022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>333333dddddd</td>\n",
       "      <td>0.139513</td>\n",
       "      <td>-1.091022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     student_id  content_5  wording_5\n",
       "0  000000ffffff   0.139513  -1.091022\n",
       "1  111111eeeeee   0.139513  -1.091022\n",
       "2  222222cccccc   0.139513  -1.091022\n",
       "3  333333dddddd   0.139513  -1.091022"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_llm.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70799d7d",
   "metadata": {
    "papermill": {
     "duration": 0.019053,
     "end_time": "2023-10-07T11:05:29.064613",
     "exception": false,
     "start_time": "2023-10-07T11:05:29.045560",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### LGBM Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7233f863",
   "metadata": {
    "papermill": {
     "duration": 0.018644,
     "end_time": "2023-10-07T11:05:29.102590",
     "exception": false,
     "start_time": "2023-10-07T11:05:29.083946",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We can also train an LGBM model on the numerical features on the dataset to make predictions. Before continuing, let's split the given dataset into train and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c3c3f12d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-07T11:05:29.137368Z",
     "iopub.status.busy": "2023-10-07T11:05:29.136709Z",
     "iopub.status.idle": "2023-10-07T11:05:29.141371Z",
     "shell.execute_reply": "2023-10-07T11:05:29.140410Z"
    },
    "papermill": {
     "duration": 0.023619,
     "end_time": "2023-10-07T11:05:29.143110",
     "exception": false,
     "start_time": "2023-10-07T11:05:29.119491",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "feature_cols = ['text_len', 'prompt_len', 'length_ratio', 'misspelled',\n",
    "                'word_overlap_count', 'bigram_overlap_count', 'trigram_overlap_count',\n",
    "               'bigram_overlap_ratio', 'trigram_overlap_ratio']\n",
    "\n",
    "targets = ['content', 'wording']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "74499377",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-07T11:05:29.177387Z",
     "iopub.status.busy": "2023-10-07T11:05:29.176556Z",
     "iopub.status.idle": "2023-10-07T11:05:29.181881Z",
     "shell.execute_reply": "2023-10-07T11:05:29.181097Z"
    },
    "papermill": {
     "duration": 0.023919,
     "end_time": "2023-10-07T11:05:29.183563",
     "exception": false,
     "start_time": "2023-10-07T11:05:29.159644",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_test = test[feature_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "69d984df",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-07T11:05:29.216903Z",
     "iopub.status.busy": "2023-10-07T11:05:29.216632Z",
     "iopub.status.idle": "2023-10-07T11:05:29.221501Z",
     "shell.execute_reply": "2023-10-07T11:05:29.220074Z"
    },
    "papermill": {
     "duration": 0.023598,
     "end_time": "2023-10-07T11:05:29.223264",
     "exception": false,
     "start_time": "2023-10-07T11:05:29.199666",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    'verbose': -1,\n",
    "    'boosting_type': 'gbdt',\n",
    "    'random_state': 42,\n",
    "    'objective': 'regression',\n",
    "    'metric': 'rmse',\n",
    "    'learning_rate': 0.048,\n",
    "    'max_depth': 4,  #3\n",
    "    'lambda_l1': 0.0,\n",
    "    'lambda_l2': 0.011\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "97216409",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-07T11:05:29.260458Z",
     "iopub.status.busy": "2023-10-07T11:05:29.259626Z",
     "iopub.status.idle": "2023-10-07T11:05:33.093874Z",
     "shell.execute_reply": "2023-10-07T11:05:33.092918Z"
    },
    "papermill": {
     "duration": 3.856314,
     "end_time": "2023-10-07T11:05:33.095810",
     "exception": false,
     "start_time": "2023-10-07T11:05:29.239496",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 1 - Train Indices: [   0    1    2 ... 7161 7163 7164], Val Indices: [   8   14   17 ... 7157 7159 7162]\n",
      "\n",
      "Training for content\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[100]\ttrain's rmse: 0.446375\n",
      "Early stopping, best iteration is:\n",
      "[125]\ttrain's rmse: 0.445928\n",
      "\n",
      "Training for wording\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[100]\ttrain's rmse: 0.59066\n",
      "Early stopping, best iteration is:\n",
      "[143]\ttrain's rmse: 0.589227\n",
      "\n",
      "Fold 2 - Train Indices: [   0    1    2 ... 7162 7163 7164], Val Indices: [  12   15   26 ... 7152 7160 7161]\n",
      "\n",
      "Training for content\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[100]\ttrain's rmse: 0.445534\n",
      "[200]\ttrain's rmse: 0.443594\n",
      "Early stopping, best iteration is:\n",
      "[195]\ttrain's rmse: 0.443439\n",
      "\n",
      "Training for wording\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[100]\ttrain's rmse: 0.6071\n",
      "[200]\ttrain's rmse: 0.601333\n",
      "Early stopping, best iteration is:\n",
      "[256]\ttrain's rmse: 0.60005\n",
      "\n",
      "Fold 3 - Train Indices: [   1    2    3 ... 7160 7161 7162], Val Indices: [   0    6    7 ... 7150 7163 7164]\n",
      "\n",
      "Training for content\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[100]\ttrain's rmse: 0.461709\n",
      "[200]\ttrain's rmse: 0.458308\n",
      "Early stopping, best iteration is:\n",
      "[192]\ttrain's rmse: 0.458217\n",
      "\n",
      "Training for wording\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[100]\ttrain's rmse: 0.598079\n",
      "Early stopping, best iteration is:\n",
      "[86]\ttrain's rmse: 0.597356\n",
      "\n",
      "Fold 4 - Train Indices: [   0    3    4 ... 7162 7163 7164], Val Indices: [   1    2   10 ... 7148 7154 7158]\n",
      "\n",
      "Training for content\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[100]\ttrain's rmse: 0.466055\n",
      "[200]\ttrain's rmse: 0.461269\n",
      "Early stopping, best iteration is:\n",
      "[215]\ttrain's rmse: 0.460855\n",
      "\n",
      "Training for wording\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[100]\ttrain's rmse: 0.633974\n",
      "Early stopping, best iteration is:\n",
      "[156]\ttrain's rmse: 0.63193\n",
      "\n",
      "Fold 5 - Train Indices: [   0    1    2 ... 7162 7163 7164], Val Indices: [   3    4    5 ... 7149 7151 7155]\n",
      "\n",
      "Training for content\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[100]\ttrain's rmse: 0.44796\n",
      "Early stopping, best iteration is:\n",
      "[129]\ttrain's rmse: 0.44693\n",
      "\n",
      "Training for wording\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[100]\ttrain's rmse: 0.589144\n",
      "Early stopping, best iteration is:\n",
      "[166]\ttrain's rmse: 0.587916\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMRegressor\n",
    "import lightgbm as lgb\n",
    "from collections import OrderedDict\n",
    "\n",
    "predictions_dict = OrderedDict()\n",
    "\n",
    "for fold, (train_index, val_index) in enumerate(kf.split(train)):\n",
    "    print(f\"\\nFold {fold + 1} - Train Indices: {train_index}, Val Indices: {val_index}\")\n",
    "    train_cv = train.iloc[train_index]\n",
    "    val_cv = train.iloc[val_index]\n",
    "    \n",
    "    for target in targets:\n",
    "        predictions = []\n",
    "        print(f\"\\nTraining for {target}\")\n",
    "        X_train_cv = train_cv[feature_cols]\n",
    "        X_val_cv = val_cv[feature_cols]\n",
    "        \n",
    "        y_train_cv = train_cv[target]\n",
    "        y_val_cv = val_cv[target]\n",
    "        \n",
    "        dtrain = lgb.Dataset(X_train_cv, label = y_train_cv)\n",
    "        dval = lgb.Dataset(X_val_cv, label = y_val_cv)\n",
    "        \n",
    "        evaluation_results = {}\n",
    "        model = lgb.train(params, num_boost_round=10000, valid_names=['train', 'valid'],\n",
    "                  train_set=dtrain,valid_sets=dval,\n",
    "                  callbacks=[lgb.early_stopping(stopping_rounds=30, verbose=True),lgb.log_evaluation(100),\n",
    "                             lgb.callback.record_evaluation(evaluation_results)],)\n",
    "        pred = model.predict(X_test)\n",
    "        predictions.extend(pred)\n",
    "        predictions_dict[f\"{target}_{fold}\"] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3b29d41d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-07T11:05:33.131188Z",
     "iopub.status.busy": "2023-10-07T11:05:33.130906Z",
     "iopub.status.idle": "2023-10-07T11:05:33.144349Z",
     "shell.execute_reply": "2023-10-07T11:05:33.143440Z"
    },
    "papermill": {
     "duration": 0.032763,
     "end_time": "2023-10-07T11:05:33.146058",
     "exception": false,
     "start_time": "2023-10-07T11:05:33.113295",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content_0</th>\n",
       "      <th>wording_0</th>\n",
       "      <th>content_1</th>\n",
       "      <th>wording_1</th>\n",
       "      <th>content_2</th>\n",
       "      <th>wording_2</th>\n",
       "      <th>content_3</th>\n",
       "      <th>wording_3</th>\n",
       "      <th>content_4</th>\n",
       "      <th>wording_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.396739</td>\n",
       "      <td>-0.900027</td>\n",
       "      <td>-1.362828</td>\n",
       "      <td>-0.988698</td>\n",
       "      <td>-1.406861</td>\n",
       "      <td>-0.855387</td>\n",
       "      <td>-1.351256</td>\n",
       "      <td>-1.132858</td>\n",
       "      <td>-1.368172</td>\n",
       "      <td>-0.991326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.396739</td>\n",
       "      <td>-0.900027</td>\n",
       "      <td>-1.362828</td>\n",
       "      <td>-0.988698</td>\n",
       "      <td>-1.406861</td>\n",
       "      <td>-0.855387</td>\n",
       "      <td>-1.351256</td>\n",
       "      <td>-1.132858</td>\n",
       "      <td>-1.368172</td>\n",
       "      <td>-0.991326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.396739</td>\n",
       "      <td>-0.900027</td>\n",
       "      <td>-1.362828</td>\n",
       "      <td>-0.988698</td>\n",
       "      <td>-1.406861</td>\n",
       "      <td>-0.855387</td>\n",
       "      <td>-1.351256</td>\n",
       "      <td>-1.132858</td>\n",
       "      <td>-1.368172</td>\n",
       "      <td>-0.991326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.396739</td>\n",
       "      <td>-0.900027</td>\n",
       "      <td>-1.362828</td>\n",
       "      <td>-0.988698</td>\n",
       "      <td>-1.406861</td>\n",
       "      <td>-0.855387</td>\n",
       "      <td>-1.351256</td>\n",
       "      <td>-1.132858</td>\n",
       "      <td>-1.368172</td>\n",
       "      <td>-0.991326</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   content_0  wording_0  content_1  wording_1  content_2  wording_2  \\\n",
       "0  -1.396739  -0.900027  -1.362828  -0.988698  -1.406861  -0.855387   \n",
       "1  -1.396739  -0.900027  -1.362828  -0.988698  -1.406861  -0.855387   \n",
       "2  -1.396739  -0.900027  -1.362828  -0.988698  -1.406861  -0.855387   \n",
       "3  -1.396739  -0.900027  -1.362828  -0.988698  -1.406861  -0.855387   \n",
       "\n",
       "   content_3  wording_3  content_4  wording_4  \n",
       "0  -1.351256  -1.132858  -1.368172  -0.991326  \n",
       "1  -1.351256  -1.132858  -1.368172  -0.991326  \n",
       "2  -1.351256  -1.132858  -1.368172  -0.991326  \n",
       "3  -1.351256  -1.132858  -1.368172  -0.991326  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_lgbm = pd.DataFrame(predictions_dict)\n",
    "submission_lgbm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8428f15c",
   "metadata": {
    "papermill": {
     "duration": 0.016254,
     "end_time": "2023-10-07T11:05:33.179357",
     "exception": false,
     "start_time": "2023-10-07T11:05:33.163103",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b614acf3",
   "metadata": {
    "papermill": {
     "duration": 0.016227,
     "end_time": "2023-10-07T11:05:33.212062",
     "exception": false,
     "start_time": "2023-10-07T11:05:33.195835",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0f64b3d8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-07T11:05:33.248381Z",
     "iopub.status.busy": "2023-10-07T11:05:33.248086Z",
     "iopub.status.idle": "2023-10-07T11:05:33.263408Z",
     "shell.execute_reply": "2023-10-07T11:05:33.262479Z"
    },
    "papermill": {
     "duration": 0.034963,
     "end_time": "2023-10-07T11:05:33.265137",
     "exception": false,
     "start_time": "2023-10-07T11:05:33.230174",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content_0</th>\n",
       "      <th>wording_0</th>\n",
       "      <th>content_1</th>\n",
       "      <th>wording_1</th>\n",
       "      <th>content_2</th>\n",
       "      <th>wording_2</th>\n",
       "      <th>content_3</th>\n",
       "      <th>wording_3</th>\n",
       "      <th>content_4</th>\n",
       "      <th>wording_4</th>\n",
       "      <th>student_id</th>\n",
       "      <th>content_5</th>\n",
       "      <th>wording_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.396739</td>\n",
       "      <td>-0.900027</td>\n",
       "      <td>-1.362828</td>\n",
       "      <td>-0.988698</td>\n",
       "      <td>-1.406861</td>\n",
       "      <td>-0.855387</td>\n",
       "      <td>-1.351256</td>\n",
       "      <td>-1.132858</td>\n",
       "      <td>-1.368172</td>\n",
       "      <td>-0.991326</td>\n",
       "      <td>000000ffffff</td>\n",
       "      <td>0.139513</td>\n",
       "      <td>-1.091022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.396739</td>\n",
       "      <td>-0.900027</td>\n",
       "      <td>-1.362828</td>\n",
       "      <td>-0.988698</td>\n",
       "      <td>-1.406861</td>\n",
       "      <td>-0.855387</td>\n",
       "      <td>-1.351256</td>\n",
       "      <td>-1.132858</td>\n",
       "      <td>-1.368172</td>\n",
       "      <td>-0.991326</td>\n",
       "      <td>111111eeeeee</td>\n",
       "      <td>0.139513</td>\n",
       "      <td>-1.091022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.396739</td>\n",
       "      <td>-0.900027</td>\n",
       "      <td>-1.362828</td>\n",
       "      <td>-0.988698</td>\n",
       "      <td>-1.406861</td>\n",
       "      <td>-0.855387</td>\n",
       "      <td>-1.351256</td>\n",
       "      <td>-1.132858</td>\n",
       "      <td>-1.368172</td>\n",
       "      <td>-0.991326</td>\n",
       "      <td>222222cccccc</td>\n",
       "      <td>0.139513</td>\n",
       "      <td>-1.091022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.396739</td>\n",
       "      <td>-0.900027</td>\n",
       "      <td>-1.362828</td>\n",
       "      <td>-0.988698</td>\n",
       "      <td>-1.406861</td>\n",
       "      <td>-0.855387</td>\n",
       "      <td>-1.351256</td>\n",
       "      <td>-1.132858</td>\n",
       "      <td>-1.368172</td>\n",
       "      <td>-0.991326</td>\n",
       "      <td>333333dddddd</td>\n",
       "      <td>0.139513</td>\n",
       "      <td>-1.091022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   content_0  wording_0  content_1  wording_1  content_2  wording_2  \\\n",
       "0  -1.396739  -0.900027  -1.362828  -0.988698  -1.406861  -0.855387   \n",
       "1  -1.396739  -0.900027  -1.362828  -0.988698  -1.406861  -0.855387   \n",
       "2  -1.396739  -0.900027  -1.362828  -0.988698  -1.406861  -0.855387   \n",
       "3  -1.396739  -0.900027  -1.362828  -0.988698  -1.406861  -0.855387   \n",
       "\n",
       "   content_3  wording_3  content_4  wording_4    student_id  content_5  \\\n",
       "0  -1.351256  -1.132858  -1.368172  -0.991326  000000ffffff   0.139513   \n",
       "1  -1.351256  -1.132858  -1.368172  -0.991326  111111eeeeee   0.139513   \n",
       "2  -1.351256  -1.132858  -1.368172  -0.991326  222222cccccc   0.139513   \n",
       "3  -1.351256  -1.132858  -1.368172  -0.991326  333333dddddd   0.139513   \n",
       "\n",
       "   wording_5  \n",
       "0  -1.091022  \n",
       "1  -1.091022  \n",
       "2  -1.091022  \n",
       "3  -1.091022  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.concat([submission_lgbm, submission_llm], axis = 1)\n",
    "\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cc0c8b76",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-07T11:05:33.300523Z",
     "iopub.status.busy": "2023-10-07T11:05:33.299824Z",
     "iopub.status.idle": "2023-10-07T11:05:33.303961Z",
     "shell.execute_reply": "2023-10-07T11:05:33.303064Z"
    },
    "papermill": {
     "duration": 0.023128,
     "end_time": "2023-10-07T11:05:33.305625",
     "exception": false,
     "start_time": "2023-10-07T11:05:33.282497",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "content_keys = ['content_0', 'content_1', 'content_2', 'content_3', 'content_4', 'content_5']\n",
    "wording_keys = ['wording_0', 'wording_1', 'wording_2', 'wording_3', 'wording_4', 'wording_5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "dc0a1028",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-07T11:05:33.340535Z",
     "iopub.status.busy": "2023-10-07T11:05:33.339992Z",
     "iopub.status.idle": "2023-10-07T11:05:33.353837Z",
     "shell.execute_reply": "2023-10-07T11:05:33.352894Z"
    },
    "papermill": {
     "duration": 0.033232,
     "end_time": "2023-10-07T11:05:33.355583",
     "exception": false,
     "start_time": "2023-10-07T11:05:33.322351",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>student_id</th>\n",
       "      <th>content</th>\n",
       "      <th>wording</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000000ffffff</td>\n",
       "      <td>-1.124391</td>\n",
       "      <td>-0.99322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>111111eeeeee</td>\n",
       "      <td>-1.124391</td>\n",
       "      <td>-0.99322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>222222cccccc</td>\n",
       "      <td>-1.124391</td>\n",
       "      <td>-0.99322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>333333dddddd</td>\n",
       "      <td>-1.124391</td>\n",
       "      <td>-0.99322</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     student_id   content  wording\n",
       "0  000000ffffff -1.124391 -0.99322\n",
       "1  111111eeeeee -1.124391 -0.99322\n",
       "2  222222cccccc -1.124391 -0.99322\n",
       "3  333333dddddd -1.124391 -0.99322"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission['content'] = submission[content_keys].mean(axis=1)\n",
    "submission['wording'] = submission[wording_keys].mean(axis = 1)\n",
    "\n",
    "submission.drop(columns = content_keys, axis = 1, inplace = True)\n",
    "submission.drop(columns = wording_keys, axis = 1, inplace = True)\n",
    "\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ca31a5f9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-07T11:05:33.390868Z",
     "iopub.status.busy": "2023-10-07T11:05:33.390499Z",
     "iopub.status.idle": "2023-10-07T11:05:33.397438Z",
     "shell.execute_reply": "2023-10-07T11:05:33.396630Z"
    },
    "papermill": {
     "duration": 0.026349,
     "end_time": "2023-10-07T11:05:33.399125",
     "exception": false,
     "start_time": "2023-10-07T11:05:33.372776",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "submission.to_csv('submission.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912f2ffe",
   "metadata": {
    "papermill": {
     "duration": 0.016778,
     "end_time": "2023-10-07T11:05:33.434703",
     "exception": false,
     "start_time": "2023-10-07T11:05:33.417925",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d4904d",
   "metadata": {
    "papermill": {
     "duration": 0.016645,
     "end_time": "2023-10-07T11:05:33.468459",
     "exception": false,
     "start_time": "2023-10-07T11:05:33.451814",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 3832.706312,
   "end_time": "2023-10-07T11:05:36.878333",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-10-07T10:01:44.172021",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
