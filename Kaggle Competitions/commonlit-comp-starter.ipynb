{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport torch \nfrom torch import nn","metadata":{"execution":{"iopub.status.busy":"2023-09-28T22:44:13.893022Z","iopub.execute_input":"2023-09-28T22:44:13.893490Z","iopub.status.idle":"2023-09-28T22:44:19.419493Z","shell.execute_reply.started":"2023-09-28T22:44:13.893452Z","shell.execute_reply":"2023-09-28T22:44:19.418495Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The goal of this notebook is to provide a prelimnary EDA and technique to go about the [Competition](https://www.kaggle.com/competitions/commonlit-evaluate-student-summaries/overview) while also learning some things from other people's work. I have tried to link to other people's work at the end of this notebook. I will be making a competition focused notebook for submission as I can't submit this one (accesses the internet) and I'm unwilling to change any part of the code in this notebook.","metadata":{}},{"cell_type":"markdown","source":"## Config","metadata":{}},{"cell_type":"code","source":"# parameters for training\n\nEPOCHS = 5\nmodel_name = 'bert-base-uncased'\nnum_labels = 2\nlearning_rate = 0.01\nBATCH_SIZE = 20\n\n# If there are GPUs available, use the first one \ndevice = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')","metadata":{"execution":{"iopub.status.busy":"2023-09-28T22:44:19.424910Z","iopub.execute_input":"2023-09-28T22:44:19.427433Z","iopub.status.idle":"2023-09-28T22:44:19.463046Z","shell.execute_reply.started":"2023-09-28T22:44:19.427396Z","shell.execute_reply":"2023-09-28T22:44:19.462007Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Loading the data and EDA","metadata":{}},{"cell_type":"code","source":"summaries = pd.read_csv('/kaggle/input/commonlit-evaluate-student-summaries/summaries_train.csv')\nprompts = pd.read_csv('/kaggle/input/commonlit-evaluate-student-summaries/prompts_train.csv')\n\nsummaries.shape, prompts.shape","metadata":{"execution":{"iopub.status.busy":"2023-09-28T22:44:19.468407Z","iopub.execute_input":"2023-09-28T22:44:19.470326Z","iopub.status.idle":"2023-09-28T22:44:19.627203Z","shell.execute_reply.started":"2023-09-28T22:44:19.470292Z","shell.execute_reply":"2023-09-28T22:44:19.626305Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"summaries.head(10)","metadata":{"execution":{"iopub.status.busy":"2023-09-28T22:44:19.632656Z","iopub.execute_input":"2023-09-28T22:44:19.635022Z","iopub.status.idle":"2023-09-28T22:44:19.662974Z","shell.execute_reply.started":"2023-09-28T22:44:19.634987Z","shell.execute_reply":"2023-09-28T22:44:19.662130Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"summaries['prompt_id'].nunique()","metadata":{"execution":{"iopub.status.busy":"2023-09-28T22:44:19.667040Z","iopub.execute_input":"2023-09-28T22:44:19.669191Z","iopub.status.idle":"2023-09-28T22:44:19.684035Z","shell.execute_reply.started":"2023-09-28T22:44:19.669157Z","shell.execute_reply":"2023-09-28T22:44:19.682933Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From this we see that we have only 4 `prompt_ids`. Let's look into the prompt_train dataset to see what they're really about","metadata":{}},{"cell_type":"code","source":"prompts.head()","metadata":{"execution":{"iopub.status.busy":"2023-09-28T22:44:19.687868Z","iopub.execute_input":"2023-09-28T22:44:19.688398Z","iopub.status.idle":"2023-09-28T22:44:19.706272Z","shell.execute_reply.started":"2023-09-28T22:44:19.688367Z","shell.execute_reply":"2023-09-28T22:44:19.705209Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's investigate about the `prompt_text` to understand more about the given dataset","metadata":{}},{"cell_type":"code","source":"prompts['prompt_text'].iloc[0]","metadata":{"execution":{"iopub.status.busy":"2023-09-28T22:44:19.710971Z","iopub.execute_input":"2023-09-28T22:44:19.711394Z","iopub.status.idle":"2023-09-28T22:44:19.718000Z","shell.execute_reply.started":"2023-09-28T22:44:19.711368Z","shell.execute_reply":"2023-09-28T22:44:19.716902Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prompts['prompt_question'].iloc[0]","metadata":{"execution":{"iopub.status.busy":"2023-09-28T22:44:19.719644Z","iopub.execute_input":"2023-09-28T22:44:19.720118Z","iopub.status.idle":"2023-09-28T22:44:19.728703Z","shell.execute_reply.started":"2023-09-28T22:44:19.720083Z","shell.execute_reply":"2023-09-28T22:44:19.727641Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"texts = summaries[summaries['prompt_id'] == '39c16e'].loc[:,['text', 'content', 'wording']].values.tolist()\n\nfor text in texts[:3]:\n    print(f\"Text: {text[0]}\")\n    print(f\"Content score: {text[1]}\")\n    print(f\"Wording score: {text[2]}\")\n    print('\\n')","metadata":{"execution":{"iopub.status.busy":"2023-09-28T22:44:19.730448Z","iopub.execute_input":"2023-09-28T22:44:19.730824Z","iopub.status.idle":"2023-09-28T22:44:19.748980Z","shell.execute_reply.started":"2023-09-28T22:44:19.730792Z","shell.execute_reply":"2023-09-28T22:44:19.747888Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"And for the second `prompt_id` in the prompt dataset","metadata":{}},{"cell_type":"code","source":"prompts['prompt_text'].iloc[1]","metadata":{"execution":{"iopub.status.busy":"2023-09-28T22:44:19.753653Z","iopub.execute_input":"2023-09-28T22:44:19.753910Z","iopub.status.idle":"2023-09-28T22:44:19.760766Z","shell.execute_reply.started":"2023-09-28T22:44:19.753887Z","shell.execute_reply":"2023-09-28T22:44:19.759633Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prompts['prompt_question'].iloc[1]","metadata":{"execution":{"iopub.status.busy":"2023-09-28T22:44:19.762000Z","iopub.execute_input":"2023-09-28T22:44:19.763027Z","iopub.status.idle":"2023-09-28T22:44:19.876437Z","shell.execute_reply.started":"2023-09-28T22:44:19.762996Z","shell.execute_reply":"2023-09-28T22:44:19.875492Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"texts = summaries[summaries['prompt_id'] == '3b9047'].loc[:,['text', 'content', 'wording']].values.tolist()\n\nfor text in texts[:3]:\n    print(f\"Text: {text[0]}\")\n    print(f\"Content score: {text[1]}\")\n    print(f\"Wording score: {text[2]}\")\n    print('\\n')","metadata":{"execution":{"iopub.status.busy":"2023-09-28T22:44:19.877801Z","iopub.execute_input":"2023-09-28T22:44:19.878201Z","iopub.status.idle":"2023-09-28T22:44:19.891251Z","shell.execute_reply.started":"2023-09-28T22:44:19.878170Z","shell.execute_reply":"2023-09-28T22:44:19.890177Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We have seen a couple of samples from the dataset. Let's dive into the `content and wording scores` from the train dataset.","metadata":{}},{"cell_type":"code","source":"summaries[['content', 'wording']].describe()","metadata":{"execution":{"iopub.status.busy":"2023-09-28T22:44:19.892735Z","iopub.execute_input":"2023-09-28T22:44:19.892994Z","iopub.status.idle":"2023-09-28T22:44:19.913168Z","shell.execute_reply.started":"2023-09-28T22:44:19.892972Z","shell.execute_reply":"2023-09-28T22:44:19.912233Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We see that the values for both `content` and `wording` ranges from about -2 to about 5.","metadata":{}},{"cell_type":"markdown","source":"Let's take a look at the entry with the lowest content scores as well as its prompt question.","metadata":{}},{"cell_type":"code","source":"entries = summaries[summaries['content'] == summaries['content'].min()].loc[:, ['prompt_id','text']].values.tolist()\n\nfor i in range(len(entries)):\n    idx = entries[i][0]\n    \n    print(f\"Prompt question: {(prompts[prompts['prompt_id'] == idx].loc[:, 'prompt_question'].values.tolist())[0]}\")\n    \n    print(f\"Summarized Text: {entries[i][1]}\")\n    \n    print('\\n')","metadata":{"execution":{"iopub.status.busy":"2023-09-28T22:44:19.914467Z","iopub.execute_input":"2023-09-28T22:44:19.915005Z","iopub.status.idle":"2023-09-28T22:44:19.926538Z","shell.execute_reply.started":"2023-09-28T22:44:19.914973Z","shell.execute_reply":"2023-09-28T22:44:19.925652Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"and the entry(s) with the max content score...","metadata":{}},{"cell_type":"code","source":"entries = summaries[summaries['content'] == summaries['content'].max()].loc[:, ['prompt_id','text']].values.tolist()\n\nfor i in range(len(entries)):\n    idx = entries[i][0]\n    \n    print(f\"Prompt question: {(prompts[prompts['prompt_id'] == idx].loc[:, 'prompt_question'].values.tolist())[0]}\")\n    \n    print(f\"Summarized Text: {entries[i][1]}\")\n    \n    print('\\n')","metadata":{"execution":{"iopub.status.busy":"2023-09-28T22:44:19.928007Z","iopub.execute_input":"2023-09-28T22:44:19.928365Z","iopub.status.idle":"2023-09-28T22:44:19.938502Z","shell.execute_reply.started":"2023-09-28T22:44:19.928333Z","shell.execute_reply":"2023-09-28T22:44:19.937552Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As we can see, the entries with the better content score has richer details compared to that with lower content score. As content score is highly correlated with wording score, there's no need to repeat this check on that feature.\n\nLet's merge the summaries with the prompts.","metadata":{}},{"cell_type":"code","source":"train = summaries.merge(prompts, on = 'prompt_id', how = 'inner')\ntrain.drop(['student_id', 'prompt_id'], axis = 1, inplace = True)\n\ntrain.head(10)","metadata":{"execution":{"iopub.status.busy":"2023-09-28T22:44:19.940003Z","iopub.execute_input":"2023-09-28T22:44:19.940542Z","iopub.status.idle":"2023-09-28T22:44:19.968501Z","shell.execute_reply.started":"2023-09-28T22:44:19.940508Z","shell.execute_reply":"2023-09-28T22:44:19.967694Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Feature Engineering","metadata":{}},{"cell_type":"code","source":"train['text_len'] = train['text'].apply(lambda x: len(x.split()))\ntrain['prompt_len'] = train['prompt_text'].apply(lambda x: len(x.split()))\ntrain['length_ratio'] = train['text_len'] / train['prompt_len']\n\ntrain.head(10)","metadata":{"execution":{"iopub.status.busy":"2023-09-28T22:44:19.969908Z","iopub.execute_input":"2023-09-28T22:44:19.970197Z","iopub.status.idle":"2023-09-28T22:44:20.273349Z","shell.execute_reply.started":"2023-09-28T22:44:19.970169Z","shell.execute_reply":"2023-09-28T22:44:20.272365Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.displot(train['text_len'])\nplt.title('Word Frequency Distribution in the dataset')\nplt.xlabel('No. of words')\nplt.ylabel('Frequency')","metadata":{"execution":{"iopub.status.busy":"2023-09-28T22:44:20.274856Z","iopub.execute_input":"2023-09-28T22:44:20.275243Z","iopub.status.idle":"2023-09-28T22:44:20.927543Z","shell.execute_reply.started":"2023-09-28T22:44:20.275209Z","shell.execute_reply":"2023-09-28T22:44:20.926642Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"corr = train[['content', 'wording', 'text_len', 'length_ratio']].corr()\n\ncorr","metadata":{"execution":{"iopub.status.busy":"2023-09-28T22:44:20.928879Z","iopub.execute_input":"2023-09-28T22:44:20.929966Z","iopub.status.idle":"2023-09-28T22:44:20.945028Z","shell.execute_reply.started":"2023-09-28T22:44:20.929930Z","shell.execute_reply":"2023-09-28T22:44:20.944162Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As we see, having a high number of words in the summary is highly correlated to having a good content and wording score. Let's see the `text` from the entry with the least and most amount of words.","metadata":{}},{"cell_type":"code","source":"entry = train[train['text_len'] == train['text_len'].max()].loc[:, ['text', 'content', 'wording']].values.tolist()\n\nfor i in range(len(entry)):\n    print(f\"Text: {entry[i][0]}\")\n    print(f\"Content score: {entry[i][1]}\")\n    print(f\"Wording score: {entry[i][2]}\")\n    \n    print('\\n')","metadata":{"execution":{"iopub.status.busy":"2023-09-28T22:44:20.946475Z","iopub.execute_input":"2023-09-28T22:44:20.946826Z","iopub.status.idle":"2023-09-28T22:44:20.955203Z","shell.execute_reply.started":"2023-09-28T22:44:20.946795Z","shell.execute_reply":"2023-09-28T22:44:20.954248Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"In this case, while the summarized entry gave a lot of details and has a high content score, his wording score was quite poor.","metadata":{}},{"cell_type":"code","source":"entry = train[train['text_len'] == train['text_len'].min()].loc[:, ['text', 'content', 'wording']].values.tolist()\n\nfor i in range(len(entry)):\n    print(f\"Text: {entry[i][0]}\")\n    print(f\"Content score: {entry[i][1]}\")\n    print(f\"Wording score: {entry[i][2]}\")\n    \n    print('\\n')","metadata":{"execution":{"iopub.status.busy":"2023-09-28T22:44:20.956914Z","iopub.execute_input":"2023-09-28T22:44:20.957576Z","iopub.status.idle":"2023-09-28T22:44:20.967901Z","shell.execute_reply.started":"2023-09-28T22:44:20.957545Z","shell.execute_reply":"2023-09-28T22:44:20.966686Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Misspell check","metadata":{}},{"cell_type":"markdown","source":"This was taken from this [notebook](https://www.kaggle.com/code/vassylkorzh/feature-engineering/notebook). ","metadata":{}},{"cell_type":"code","source":"!pip install pyspellchecker","metadata":{"execution":{"iopub.status.busy":"2023-09-28T22:44:20.969514Z","iopub.execute_input":"2023-09-28T22:44:20.970018Z","iopub.status.idle":"2023-09-28T22:44:34.699329Z","shell.execute_reply.started":"2023-09-28T22:44:20.969988Z","shell.execute_reply":"2023-09-28T22:44:34.697938Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from spellchecker import SpellChecker","metadata":{"execution":{"iopub.status.busy":"2023-09-28T22:44:34.700857Z","iopub.execute_input":"2023-09-28T22:44:34.701156Z","iopub.status.idle":"2023-09-28T22:44:34.713684Z","shell.execute_reply.started":"2023-09-28T22:44:34.701126Z","shell.execute_reply":"2023-09-28T22:44:34.712819Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import nltk","metadata":{"execution":{"iopub.status.busy":"2023-09-28T22:44:34.715088Z","iopub.execute_input":"2023-09-28T22:44:34.715764Z","iopub.status.idle":"2023-09-28T22:44:35.304700Z","shell.execute_reply.started":"2023-09-28T22:44:34.715732Z","shell.execute_reply":"2023-09-28T22:44:35.303515Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"spellchecker = SpellChecker()\n\ndef get_misspelled_count(text):\n    tokens = nltk.word_tokenize(text)\n    misspelled = [token for token in spellchecker.unknown(tokens) if token.isalpha()]\n    \n    return len(misspelled)","metadata":{"execution":{"iopub.status.busy":"2023-09-28T22:44:35.305954Z","iopub.execute_input":"2023-09-28T22:44:35.307194Z","iopub.status.idle":"2023-09-28T22:44:35.391575Z","shell.execute_reply.started":"2023-09-28T22:44:35.307157Z","shell.execute_reply":"2023-09-28T22:44:35.390615Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train['misspelled'] = train['text'].apply(lambda x: get_misspelled_count(x))","metadata":{"execution":{"iopub.status.busy":"2023-09-28T22:44:35.394143Z","iopub.execute_input":"2023-09-28T22:44:35.394866Z","iopub.status.idle":"2023-09-28T22:44:43.622375Z","shell.execute_reply.started":"2023-09-28T22:44:35.394833Z","shell.execute_reply":"2023-09-28T22:44:43.621477Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head(10)","metadata":{"execution":{"iopub.status.busy":"2023-09-28T22:44:43.623624Z","iopub.execute_input":"2023-09-28T22:44:43.624608Z","iopub.status.idle":"2023-09-28T22:44:43.644479Z","shell.execute_reply.started":"2023-09-28T22:44:43.624559Z","shell.execute_reply":"2023-09-28T22:44:43.643575Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"corr = train[['text_len', 'length_ratio', 'misspelled', 'content', 'wording']].corr()\n\ncorr","metadata":{"execution":{"iopub.status.busy":"2023-09-28T22:44:43.651436Z","iopub.execute_input":"2023-09-28T22:44:43.651710Z","iopub.status.idle":"2023-09-28T22:44:43.667840Z","shell.execute_reply.started":"2023-09-28T22:44:43.651687Z","shell.execute_reply":"2023-09-28T22:44:43.666824Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"[More Feature Engineering ideas](https://www.kaggle.com/code/vassylkorzh/feature-engineering/notebook)","metadata":{}},{"cell_type":"markdown","source":"## Text Preprocessing","metadata":{}},{"cell_type":"code","source":"from transformers import AutoTokenizer\n\n\ntokenizer = AutoTokenizer.from_pretrained(model_name)","metadata":{"execution":{"iopub.status.busy":"2023-09-28T22:44:43.669534Z","iopub.execute_input":"2023-09-28T22:44:43.670139Z","iopub.status.idle":"2023-09-28T22:44:50.078410Z","shell.execute_reply.started":"2023-09-28T22:44:43.670104Z","shell.execute_reply":"2023-09-28T22:44:50.077406Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import Dataset\n\nclass TextDataset(Dataset):\n    def __init__(self, texts, feature_cols, targets, tokenizer, max_length):\n        self.texts = texts\n        self.feature_cols = feature_cols\n        self.targets = targets\n        self.tokenizer = tokenizer\n        self.max_length = max_length\n        \n    def __len__(self):\n        return len(self.texts)\n    \n    def __getitem__(self, idx):\n        text = self.texts[idx]\n        \n        encoding = self.tokenizer.encode_plus(text,\n                                             add_special_tokens = True,\n                                             max_length = self.max_length,\n                                             return_token_type_ids = False,\n                                             padding = 'max_length',\n                                             truncation = True,\n                                             return_attention_mask = True,\n                                             return_tensors = 'pt')\n        \n        item = {'input_ids': encoding['input_ids'].flatten(),\n               'attention_mask': encoding['attention_mask'].flatten(),\n               'feature_cols': torch.tensor(self.feature_cols[idx], dtype=torch.float), \n               'target': torch.tensor(self.targets[idx], dtype=torch.float)}\n        \n        return item","metadata":{"execution":{"iopub.status.busy":"2023-09-28T22:44:50.079910Z","iopub.execute_input":"2023-09-28T22:44:50.080601Z","iopub.status.idle":"2023-09-28T22:44:50.091164Z","shell.execute_reply.started":"2023-09-28T22:44:50.080545Z","shell.execute_reply":"2023-09-28T22:44:50.090098Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"execution":{"iopub.status.busy":"2023-09-28T22:44:50.092679Z","iopub.execute_input":"2023-09-28T22:44:50.093017Z","iopub.status.idle":"2023-09-28T22:44:50.111239Z","shell.execute_reply.started":"2023-09-28T22:44:50.092986Z","shell.execute_reply":"2023-09-28T22:44:50.110247Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"feature_cols = ['text_len', 'prompt_len', 'length_ratio', 'misspelled']\ntargets = ['content', 'wording']\nMAX_LENGTH = 512\nfeature_col_size = len(feature_cols)\n\ndataset = TextDataset(texts = train['text'],\n                     feature_cols = train[feature_cols].values,\n                     targets = train[targets].values,\n                     tokenizer = tokenizer,\n                     max_length = MAX_LENGTH)","metadata":{"execution":{"iopub.status.busy":"2023-09-28T22:44:50.112856Z","iopub.execute_input":"2023-09-28T22:44:50.113202Z","iopub.status.idle":"2023-09-28T22:44:50.124614Z","shell.execute_reply.started":"2023-09-28T22:44:50.113160Z","shell.execute_reply":"2023-09-28T22:44:50.123742Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset[1]","metadata":{"execution":{"iopub.status.busy":"2023-09-28T22:44:50.126148Z","iopub.execute_input":"2023-09-28T22:44:50.126487Z","iopub.status.idle":"2023-09-28T22:44:50.222033Z","shell.execute_reply.started":"2023-09-28T22:44:50.126457Z","shell.execute_reply":"2023-09-28T22:44:50.221114Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Modelling","metadata":{}},{"cell_type":"code","source":"from transformers import AutoModelForSequenceClassification","metadata":{"execution":{"iopub.status.busy":"2023-09-28T22:44:50.223241Z","iopub.execute_input":"2023-09-28T22:44:50.223857Z","iopub.status.idle":"2023-09-28T22:44:50.242726Z","shell.execute_reply.started":"2023-09-28T22:44:50.223823Z","shell.execute_reply":"2023-09-28T22:44:50.241759Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CustomModel(nn.Module):\n    def __init__(self, model_name, num_labels, feature_col_size):\n        \"\"\"Instantiate a model that can fit on the dataset\"\"\"\n        \n        super().__init__()\n        self.model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels = num_labels)\n        self.numerics = nn.Linear(feature_col_size, 16)\n        self.final_layer = nn.Linear(16 + num_labels, num_labels)\n        \n    def forward(self, input_ids, attention_mask, feature_cols):\n        text_output = self.model(input_ids = input_ids, attention_mask = attention_mask)\n        numerics = self.numerics(feature_cols)\n        concat_features = torch.cat([text_output.logits, numerics], dim = 1)\n        \n        final_output = self.final_layer(concat_features)\n        \n        return final_output","metadata":{"execution":{"iopub.status.busy":"2023-09-28T22:44:50.244488Z","iopub.execute_input":"2023-09-28T22:44:50.245055Z","iopub.status.idle":"2023-09-28T22:44:50.253201Z","shell.execute_reply.started":"2023-09-28T22:44:50.245022Z","shell.execute_reply":"2023-09-28T22:44:50.251923Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = CustomModel(model_name, num_labels, feature_col_size)\nmodel.to(device)","metadata":{"execution":{"iopub.status.busy":"2023-09-28T22:44:50.254751Z","iopub.execute_input":"2023-09-28T22:44:50.255081Z","iopub.status.idle":"2023-09-28T22:45:09.872800Z","shell.execute_reply.started":"2023-09-28T22:44:50.255049Z","shell.execute_reply":"2023-09-28T22:45:09.871553Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# loss and optimizer\n\nfrom torch.optim import Adam\nfrom torch.nn import MSELoss\n\n\noptimizer = Adam(model.parameters(), lr = learning_rate)\nloss_function = MSELoss()","metadata":{"execution":{"iopub.status.busy":"2023-09-28T22:45:09.874056Z","iopub.execute_input":"2023-09-28T22:45:09.874425Z","iopub.status.idle":"2023-09-28T22:45:09.882920Z","shell.execute_reply.started":"2023-09-28T22:45:09.874392Z","shell.execute_reply":"2023-09-28T22:45:09.882012Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# split the dataset to train and validation dataset\n\nfrom sklearn.model_selection import train_test_split\n\ntrain_dataset, val_dataset = train_test_split(dataset, test_size = 0.2, shuffle = True, random_state = 42)","metadata":{"execution":{"iopub.status.busy":"2023-09-28T22:45:09.884454Z","iopub.execute_input":"2023-09-28T22:45:09.885177Z","iopub.status.idle":"2023-09-28T22:45:17.911627Z","shell.execute_reply.started":"2023-09-28T22:45:09.885134Z","shell.execute_reply":"2023-09-28T22:45:17.910435Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(train_dataset), len(val_dataset))","metadata":{"execution":{"iopub.status.busy":"2023-09-28T22:45:17.913107Z","iopub.execute_input":"2023-09-28T22:45:17.913436Z","iopub.status.idle":"2023-09-28T22:45:17.921574Z","shell.execute_reply.started":"2023-09-28T22:45:17.913402Z","shell.execute_reply":"2023-09-28T22:45:17.920468Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# load the dataset using pytorch's dataloader tool\n\nfrom torch.utils.data import DataLoader\n\ntrain_loader = DataLoader(train_dataset, batch_size = BATCH_SIZE)\nval_loader = DataLoader(val_dataset, batch_size = BATCH_SIZE)","metadata":{"execution":{"iopub.status.busy":"2023-09-28T22:45:17.923295Z","iopub.execute_input":"2023-09-28T22:45:17.923652Z","iopub.status.idle":"2023-09-28T22:45:17.932357Z","shell.execute_reply.started":"2023-09-28T22:45:17.923619Z","shell.execute_reply":"2023-09-28T22:45:17.931399Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We have `len(train_dataset)//batch_size` steps in training the dataset. From above, this is about 286 steps","metadata":{}},{"cell_type":"code","source":"def train_step(train_loader):\n    \"\"\"The training loop for the dataset\"\"\"\n    \n    for step, batch in enumerate(train_loader):\n        epochal_loss = 0\n        \n        input_ids = batch['input_ids'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n        feature_cols = batch['feature_cols'].to(device)\n        targets = batch['target'].to(device)\n        \n        optimizer.zero_grad()\n        \n        outputs = model(input_ids, attention_mask, feature_cols)\n        loss = loss_function(outputs, targets)\n        epochal_loss += loss\n        loss.backward()\n        \n        optimizer.step()\n        \n        if step % 50 == 0:\n            print(f\"Epoch {epoch + 1} Step {step} Loss {loss.item()}\")\n            \n    print(f\"Epoch {epoch + 1} Train Loss: {epochal_loss/len(train_loader)}\")","metadata":{"execution":{"iopub.status.busy":"2023-09-28T22:45:17.933710Z","iopub.execute_input":"2023-09-28T22:45:17.934213Z","iopub.status.idle":"2023-09-28T22:45:17.944574Z","shell.execute_reply.started":"2023-09-28T22:45:17.934181Z","shell.execute_reply":"2023-09-28T22:45:17.943724Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def val_step(val_loader):\n    \"\"\"The validation loop\"\"\"\n    \n    with torch.no_grad():\n        for step, batch in enumerate(val_loader):\n            epochal_loss = 0\n            \n            input_ids = batch['input_ids'].to(device)\n            attention_mask = batch['attention_mask'].to(device)\n            feature_cols = batch['feature_cols'].to(device)\n            targets = batch['target'].to(device)\n            \n            optimizer.zero_grad()\n            outputs = model(input_ids, attention_mask, feature_cols)\n            loss = loss_function(outputs, targets)\n            epochal_loss += loss\n        \n        print(f\"Epoch {epoch + 1} Validation Loss: {epochal_loss/len(val_loader)}\")\n        print('\\n')","metadata":{"execution":{"iopub.status.busy":"2023-09-28T22:45:17.946128Z","iopub.execute_input":"2023-09-28T22:45:17.946452Z","iopub.status.idle":"2023-09-28T22:45:17.958541Z","shell.execute_reply.started":"2023-09-28T22:45:17.946423Z","shell.execute_reply":"2023-09-28T22:45:17.957535Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import time\n\nfor epoch in range(EPOCHS):\n    start = time.time()\n    \n    train_step(train_loader)\n    val_step(val_loader)\n    print(f\"Total time for training epoch {epoch + 1}: {time.time() - start}s\")\n    print('\\n')","metadata":{"execution":{"iopub.status.busy":"2023-09-28T22:45:17.960006Z","iopub.execute_input":"2023-09-28T22:45:17.960337Z","iopub.status.idle":"2023-09-28T23:11:04.128517Z","shell.execute_reply.started":"2023-09-28T22:45:17.960306Z","shell.execute_reply":"2023-09-28T23:11:04.127549Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Evaluation","metadata":{}},{"cell_type":"code","source":"test_summaries = pd.read_csv('/kaggle/input/commonlit-evaluate-student-summaries/summaries_test.csv')\ntest_prompt = pd.read_csv('/kaggle/input/commonlit-evaluate-student-summaries/prompts_test.csv')\n\n\n# feature engineering on the test set\n\ntest = test_summaries.merge(test_prompt, on = 'prompt_id', how = 'inner')\ntest.drop(['student_id', 'prompt_id'], axis = 1, inplace = True)\n\ntest['text_len'] = test['text'].apply(lambda x: len(x.split()))\ntest['prompt_len'] = test['prompt_text'].apply(lambda x: len(x.split()))\ntest['length_ratio'] = test['text_len'] / train['prompt_len']\n\ntest['misspelled'] = test['text'].apply(lambda x: get_misspelled_count(x))","metadata":{"execution":{"iopub.status.busy":"2023-09-28T23:11:04.129939Z","iopub.execute_input":"2023-09-28T23:11:04.131849Z","iopub.status.idle":"2023-09-28T23:11:04.163080Z","shell.execute_reply.started":"2023-09-28T23:11:04.131813Z","shell.execute_reply":"2023-09-28T23:11:04.162122Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class TestTextDataset(Dataset):\n    def __init__(self, texts, feature_cols, tokenizer, max_length):\n        self.texts = texts\n        self.feature_cols = feature_cols\n        self.tokenizer = tokenizer\n        self.max_length = max_length\n        \n    def __len__(self):\n        return len(self.texts)\n    \n    def __getitem__(self, idx):\n        text = self.texts[idx]\n        \n        encoding = self.tokenizer.encode_plus(text,\n                                             add_special_tokens = True,\n                                             max_length = self.max_length,\n                                             return_token_type_ids = False,\n                                             padding = 'max_length',\n                                             truncation = True,\n                                             return_attention_mask = True,\n                                             return_tensors = 'pt')\n        \n        item = {'input_ids': encoding['input_ids'].flatten(),\n               'attention_mask': encoding['attention_mask'].flatten(),\n               'feature_cols': torch.tensor(self.feature_cols[idx], dtype=torch.float)\n               }\n        \n        return item","metadata":{"execution":{"iopub.status.busy":"2023-09-28T23:11:04.164259Z","iopub.execute_input":"2023-09-28T23:11:04.164523Z","iopub.status.idle":"2023-09-28T23:11:04.173450Z","shell.execute_reply.started":"2023-09-28T23:11:04.164499Z","shell.execute_reply":"2023-09-28T23:11:04.172465Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_dataset = TestTextDataset(test['text'],\n                              test[feature_cols].values,\n                              tokenizer,\n                              MAX_LENGTH)\ntest_loader = DataLoader(test_dataset)","metadata":{"execution":{"iopub.status.busy":"2023-09-28T23:11:04.174910Z","iopub.execute_input":"2023-09-28T23:11:04.176055Z","iopub.status.idle":"2023-09-28T23:11:04.185871Z","shell.execute_reply.started":"2023-09-28T23:11:04.176018Z","shell.execute_reply":"2023-09-28T23:11:04.184969Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds = []\n\nfor batch in test_loader:\n    with torch.no_grad():\n        input_ids = batch['input_ids'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n        feature_cols = batch['feature_cols'].to(device)\n        \n        outputs = model(input_ids, attention_mask, feature_cols)\n        preds.extend(outputs.cpu().numpy())","metadata":{"execution":{"iopub.status.busy":"2023-09-28T23:11:04.187083Z","iopub.execute_input":"2023-09-28T23:11:04.187531Z","iopub.status.idle":"2023-09-28T23:11:04.287181Z","shell.execute_reply.started":"2023-09-28T23:11:04.187500Z","shell.execute_reply":"2023-09-28T23:11:04.286287Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds","metadata":{"execution":{"iopub.status.busy":"2023-09-28T23:11:04.288395Z","iopub.execute_input":"2023-09-28T23:11:04.288730Z","iopub.status.idle":"2023-09-28T23:11:04.299969Z","shell.execute_reply.started":"2023-09-28T23:11:04.288698Z","shell.execute_reply":"2023-09-28T23:11:04.299037Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Submission","metadata":{}},{"cell_type":"code","source":"preds[0]","metadata":{"execution":{"iopub.status.busy":"2023-09-28T23:11:04.301826Z","iopub.execute_input":"2023-09-28T23:11:04.302488Z","iopub.status.idle":"2023-09-28T23:11:04.313065Z","shell.execute_reply.started":"2023-09-28T23:11:04.302452Z","shell.execute_reply":"2023-09-28T23:11:04.312079Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.DataFrame({\n    'student_id': test_summaries['student_id'],\n    'content': [pred[0] for pred in preds],\n    'wording': [pred[1] for pred in preds]\n})","metadata":{"execution":{"iopub.status.busy":"2023-09-28T23:11:04.314471Z","iopub.execute_input":"2023-09-28T23:11:04.314744Z","iopub.status.idle":"2023-09-28T23:11:04.322347Z","shell.execute_reply.started":"2023-09-28T23:11:04.314722Z","shell.execute_reply":"2023-09-28T23:11:04.321313Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission","metadata":{"execution":{"iopub.status.busy":"2023-09-28T23:11:04.323684Z","iopub.execute_input":"2023-09-28T23:11:04.324178Z","iopub.status.idle":"2023-09-28T23:11:04.338210Z","shell.execute_reply.started":"2023-09-28T23:11:04.324117Z","shell.execute_reply":"2023-09-28T23:11:04.337213Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.to_csv('submission.csv', index = False)","metadata":{"execution":{"iopub.status.busy":"2023-09-28T23:11:04.339882Z","iopub.execute_input":"2023-09-28T23:11:04.340178Z","iopub.status.idle":"2023-09-28T23:11:04.349042Z","shell.execute_reply.started":"2023-09-28T23:11:04.340155Z","shell.execute_reply":"2023-09-28T23:11:04.348010Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Resources\n\n1. [Beginner Friendly BERT](https://www.kaggle.com/code/suraj520/beginner-friendly-bert)\n2. [Deberta + Additional features](https://www.kaggle.com/code/suraj520/beginner-friendly-bert)","metadata":{}}]}